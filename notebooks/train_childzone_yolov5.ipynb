{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/changsin/ClassifyImages/blob/main/notebooks/train_dashboard_top15.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "l3IR2E-4bPaO"
      },
      "source": [
        "# ChildZone Data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmr3ahqma9uk"
      },
      "source": [
        "# Setup\n",
        "Install requirements and prepare the dataset for training.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPDC6ckKkr1l",
        "outputId": "dd29a929-71ed-4e77-e79f-fa718a3deafd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7fNDvNWOWvpl"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output \n",
        "\n",
        "!pip install pafy\n",
        "!pip install -q youtube-dl\n",
        "\n",
        "!pip install yolov5\n",
        "\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Sp8S964yARl",
        "outputId": "d72a589e-2b3e-47eb-9372-ccebe8370387"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setup complete. Using torch 1.9.0+cu111 (Tesla P100-PCIE-16GB)\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ultralytics/yolov5  # clone repo\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt  # install dependencies\n",
        "\n",
        "import torch\n",
        "from IPython.display import Image, clear_output  # to display images\n",
        "\n",
        "clear_output()\n",
        "print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccpQvXLlatKP"
      },
      "source": [
        "Download pretrained yolov5 model\n",
        "Choose one of the pretrained models from https://github.com/ultralytics/yolov5#inference\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5pTcJ1fyG5T",
        "outputId": "69a60b5d-abfc-49cc-8368-862baa7578b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2021-10-16 07:51:43--  https://github.com/ultralytics/yolov5/releases/download/v5.0/yolov5s.pt\n",
            "Resolving github.com (github.com)... 192.30.255.112\n",
            "Connecting to github.com (github.com)|192.30.255.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-releases.githubusercontent.com/264818686/56dd3480-9af3-11eb-9c92-3ecd167961dc?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20211016%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20211016T075143Z&X-Amz-Expires=300&X-Amz-Signature=d0896974b764f558700d3af775b495cdb6afb8b78e64ba99cc91ba7327ac3102&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=264818686&response-content-disposition=attachment%3B%20filename%3Dyolov5s.pt&response-content-type=application%2Foctet-stream [following]\n",
            "--2021-10-16 07:51:43--  https://github-releases.githubusercontent.com/264818686/56dd3480-9af3-11eb-9c92-3ecd167961dc?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20211016%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20211016T075143Z&X-Amz-Expires=300&X-Amz-Signature=d0896974b764f558700d3af775b495cdb6afb8b78e64ba99cc91ba7327ac3102&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=264818686&response-content-disposition=attachment%3B%20filename%3Dyolov5s.pt&response-content-type=application%2Foctet-stream\n",
            "Resolving github-releases.githubusercontent.com (github-releases.githubusercontent.com)... 185.199.108.154, 185.199.111.154, 185.199.109.154, ...\n",
            "Connecting to github-releases.githubusercontent.com (github-releases.githubusercontent.com)|185.199.108.154|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14795158 (14M) [application/octet-stream]\n",
            "Saving to: ‘yolov5s.pt’\n",
            "\n",
            "yolov5s.pt          100%[===================>]  14.11M  76.4MB/s    in 0.2s    \n",
            "\n",
            "2021-10-16 07:51:43 (76.4 MB/s) - ‘yolov5s.pt’ saved [14795158/14795158]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/ultralytics/yolov5/releases/download/v5.0/yolov5s.pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/aidev/data/AI-Hub/ChildZoneCCTV/split\n",
            "/home/aidev/data/AI-Hub/ChildZoneCCTV/split\n",
            "total 20\n",
            "drwxrwxr-x 5 aidev aidev 4096  2월  3 12:51 .\n",
            "drwxrwxr-x 3 aidev aidev 4096  2월  3 12:07 ..\n",
            "drwxrwxr-x 9 aidev aidev 4096  2월  3 12:11 test\n",
            "drwxrwxr-x 9 aidev aidev 4096  2월  3 12:45 train\n",
            "drwxrwxr-x 9 aidev aidev 4096  2월  3 12:55 val\n"
          ]
        }
      ],
      "source": [
        "%cd /home/aidev/data/AI-Hub/ChildZoneCCTV/split\n",
        "!pwd\n",
        "!ls -al"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1SYBEUwDcFwq"
      },
      "outputs": [],
      "source": [
        "DATA_ROOT = \"/home/aidev/data/AI-Hub/ChildZoneCCTV/split/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qdNGi08turU"
      },
      "source": [
        "## Copy files (One time)\n",
        "\n",
        "To make val and test folders flat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JS8FNRNBm-z2"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "\n",
        "def glob_files(folder, file_type='*'):\n",
        "    search_string = os.path.join(folder, file_type)\n",
        "    files = glob.glob(search_string)\n",
        "\n",
        "    print('Searching ', search_string)\n",
        "    paths = []\n",
        "    for f in files:\n",
        "      if os.path.isdir(f):\n",
        "        sub_paths = glob_files(f + '/')\n",
        "        paths += sub_paths\n",
        "      else:\n",
        "        paths.append(f)\n",
        "\n",
        "    # We sort the images in alphabetical order to match them\n",
        "    #  to the annotation files\n",
        "    paths.sort()\n",
        "\n",
        "    return paths\n",
        "\n",
        "\n",
        "def glob_folders(folder, file_type='*'):\n",
        "    search_string = os.path.join(folder, file_type)\n",
        "    files = glob.glob(search_string)\n",
        "\n",
        "    print('Searching ', search_string)\n",
        "    paths = []\n",
        "    for f in files:\n",
        "      if os.path.isdir(f):\n",
        "        paths.append(f)\n",
        "\n",
        "    # We sort the images in alphabetical order to match them\n",
        "    #  to the annotation files\n",
        "    paths.sort()\n",
        "\n",
        "    return paths\n",
        "\n",
        "def split_val_files(parent_folder, folder_from, folder_to):\n",
        "  folder_to = os.path.join(parent_folder, folder_to)\n",
        "  if not os.path.exists(folder_to):\n",
        "    print(\"Creating folder to \", folder_to)\n",
        "    os.mkdir(folder_to)\n",
        "\n",
        "  sub_folders = glob_folders(folder_from)\n",
        "  copied_count = 0\n",
        "\n",
        "  for sub_id, sub_folder in enumerate(sub_folders):\n",
        "    files = glob_files(sub_folder)\n",
        "  \n",
        "    # end_id = int(len(files) * 0.2)\n",
        "    end_id = len(files)\n",
        "    print(\"Copying {} files\".format(end_id))\n",
        "\n",
        "    sub_folder_to = os.path.join(folder_to, \"{}_{}\"\n",
        "      .format(os.path.basename(folder_to), sub_id))\n",
        "    if not os.path.exists(sub_folder_to):\n",
        "      print(\"Creating folder to \", sub_folder_to)\n",
        "      os.mkdir(sub_folder_to)\n",
        "\n",
        "    for id in range(end_id):\n",
        "      file_from = files[id]\n",
        "      file_to = os.path.join(sub_folder_to, os.path.basename(file_from))\n",
        "\n",
        "      if os.path.exists(file_to):\n",
        "        print(\"ERROR: target {} already exists\".format(file_to))\n",
        "        print(\"Skipping\")\n",
        "        continue\n",
        "        # exit(-1)\n",
        "\n",
        "      else:\n",
        "        print(file_from, file_to)\n",
        "        shutil.copy(file_from, file_to)\n",
        "    copied_count += end_id\n",
        "\n",
        "  print(\"Copied \", copied_count)\n",
        "\n",
        "\n",
        "def copy_data_files(folder_from, folder_to):\n",
        "  sub_folders = glob_folders(folder_from)\n",
        "  copied_count = 0\n",
        "\n",
        "  for sub_folder in sub_folders:\n",
        "    files = glob_files(sub_folder)\n",
        "\n",
        "    for file_from in files:\n",
        "      if os.path.exists(file_from):\n",
        "          file_to = os.path.join(folder_to, os.path.basename(file_from))\n",
        "\n",
        "          if os.path.exists(file_to):\n",
        "            print(\"ERROR: target {} already exists\".format(file_to))\n",
        "            print(\"Skipping\")\n",
        "            continue\n",
        "            # exit(-1)\n",
        "\n",
        "          shutil.copy(file_from, file_to)\n",
        "          copied_count += 1\n",
        "\n",
        "  print(\"Copied \", copied_count)\n",
        "\n",
        "split_val_files(\"/content/drive/MyDrive/data/Top15\",\n",
        "                \"/content/drive/MyDrive/data/Top15/train_a_seatbelt\",\n",
        "                # \"/content/drive/MyDrive/data/Top15/val_a_seatbelt\")\n",
        "                \"/content/drive/MyDrive/data/Top15/train_a_seatbelt1\")\n",
        "# copy_data_files(DATA_ROOT + \"test_raw\", DATA_ROOT + \"test\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wD1pTl7FuAVc"
      },
      "source": [
        "# Train Dashboard Labels Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Ao-CwRDAt5Lt"
      },
      "outputs": [],
      "source": [
        "import yaml\n",
        "import subprocess\n",
        "\n",
        "def create_yaml(yaml_from, yaml_to, to_set):\n",
        "  with open(yaml_from) as fr:\n",
        "      train_config = yaml.safe_load(fr)\n",
        "\n",
        "      for key, value in to_set.items():\n",
        "        print(\"Set {} to {}\".format(key, value))\n",
        "        train_config[key] = value\n",
        "\n",
        "      with open(yaml_to, 'w') as fw:\n",
        "        fw.write(str(train_config))\n",
        "\n",
        "def launch_process(command):\n",
        "  print(command)\n",
        "  process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE)\n",
        "  process.wait()\n",
        "  for line in process.stdout:\n",
        "      print(str(line))\n",
        "\n",
        "  print(process.stderr)\n",
        "\n",
        "  return process.stdout, process.returncode\n",
        "\n",
        "def to_file(file_to, data):\n",
        "  with open(file_to, 'w') as f:\n",
        "    f.write(str(data))\n",
        "\n",
        "def train_yolo(train_data_path, val_data_path, batch_size=10, epochs=100, weights_path=None):\n",
        "  data_yaml = DATA_ROOT + \"train_data.yaml\"\n",
        "  to_set = dict({\"train\": train_data_path, \"val\": val_data_path})\n",
        "  create_yaml(\"/home/aidev/workspace/ClassifyImages/data/configs/yolov5_child_zone.yaml\", data_yaml, to_set)\n",
        "\n",
        "  cfg_yaml = DATA_ROOT + \"train_cfg.yaml\"\n",
        "  create_yaml(\"/home/aidev/workspace/ClassifyImages/data/configs/train_cfg_child_zone.yaml\", cfg_yaml, dict({\"nc\": 10}))\n",
        "\n",
        "  if weights_path is None:\n",
        "    weights_path = \"yolov5s.pt\"\n",
        "\n",
        "  !python3 train.py --img 640 --batch $batch_size --epochs $epochs --data $data_yaml --cfg $cfg_yaml --weights $weights_path --cache\n",
        "\n",
        "# !rm -rf runs/train\n",
        "# train_yolo(DATA_ROOT+\"/train\", DATA_ROOT+\"/val\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94T2yMxwGen3",
        "outputId": "70618e34-b203-4645-d707-73c5ad22d905"
      },
      "outputs": [],
      "source": [
        "!ls -Q $train_folder | head -10 | xargs -I {} echo {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%cd /home/aidev/workspace/yolov5\n",
        "!pwd\n",
        "!ls -al"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Train"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Install Weights & Biases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: wandb in /home/aidev/.local/lib/python3.10/site-packages (0.12.17)\n",
            "Requirement already satisfied: GitPython>=1.0.0 in /home/aidev/.local/lib/python3.10/site-packages (from wandb) (3.1.30)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /home/aidev/.local/lib/python3.10/site-packages (from wandb) (5.9.4)\n",
            "Requirement already satisfied: setproctitle in /home/aidev/.local/lib/python3.10/site-packages (from wandb) (1.3.2)\n",
            "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from wandb) (59.6.0)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/lib/python3/dist-packages (from wandb) (2.25.1)\n",
            "Requirement already satisfied: shortuuid>=0.5.0 in /home/aidev/.local/lib/python3.10/site-packages (from wandb) (1.0.11)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /home/aidev/.local/lib/python3.10/site-packages (from wandb) (8.0.4)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /home/aidev/.local/lib/python3.10/site-packages (from wandb) (1.14.0)\n",
            "Requirement already satisfied: pathtools in /home/aidev/.local/lib/python3.10/site-packages (from wandb) (0.1.2)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /home/aidev/.local/lib/python3.10/site-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: protobuf<4.0dev,>=3.12.0 in /home/aidev/.local/lib/python3.10/site-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: PyYAML in /usr/lib/python3/dist-packages (from wandb) (5.4.1)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /home/aidev/.local/lib/python3.10/site-packages (from wandb) (2.8.2)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/lib/python3/dist-packages (from wandb) (1.16.0)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /home/aidev/.local/lib/python3.10/site-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/aidev/.local/lib/python3.10/site-packages (from GitPython>=1.0.0->wandb) (4.0.10)\n",
            "Requirement already satisfied: urllib3>=1.26.11 in /home/aidev/.local/lib/python3.10/site-packages (from sentry-sdk>=1.0.0->wandb) (1.26.14)\n",
            "Requirement already satisfied: certifi in /usr/lib/python3/dist-packages (from sentry-sdk>=1.0.0->wandb) (2020.6.20)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /home/aidev/.local/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install wandb"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Really Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VErMf-CIlVlG",
        "outputId": "cd5ca339-8ddb-4e4d-fd21-4f51db7ff3c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Set train to /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train\n",
            "Set val to /home/aidev/data/AI-Hub/ChildZoneCCTV/split/val\n",
            "Set nc to 10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mchangsin\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=/home/aidev/data/AI-Hub/ChildZoneCCTV/split/train_cfg.yaml, data=/home/aidev/data/AI-Hub/ChildZoneCCTV/split/train_data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=100, batch_size=10, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
            "YOLOv5 🚀 v7.0-72-g064365d8 Python-3.10.6 torch-1.13.1+cu117 CUDA:0 (NVIDIA GeForce RTX 3080 Ti, 12037MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "2023-02-04 15:19:28.090716: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-02-04 15:19:28.512812: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/aidev/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
            "2023-02-04 15:19:28.512860: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/aidev/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
            "2023-02-04 15:19:28.512867: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-02-04 15:19:30.022877: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-02-04 15:19:30.097182: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/aidev/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
            "2023-02-04 15:19:30.097203: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
            "2023-02-04 15:19:30.403645: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/aidev/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
            "2023-02-04 15:19:30.403688: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/aidev/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
            "2023-02-04 15:19:30.403694: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.13.9 is available!  To upgrade, please run:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.17\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/aidev/workspace/yolov5/wandb/run-20230204_151928-1p5eu6f8\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mlunar-festival-370\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/changsin/YOLOv5\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/changsin/YOLOv5/runs/1p5eu6f8\u001b[0m\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
            "  9                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     40455  models.yolo.Detect                      [10, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "train_cfg summary: 225 layers, 7087815 parameters, 7087815 gradients\n",
            "\n",
            "Transferred 308/361 items from yolov5s.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 59 weight(decay=0.0), 62 weight(decay=0.00046875), 62 bias\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_21_\u001b[0m\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00091.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00095.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00096.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00097.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00098.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00099.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00100.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00101.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00102.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00103.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00104.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00105.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00106.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00107.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00108.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00110.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00111.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00112.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00113.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00114.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00115.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00117.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00118.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00119.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00121.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00122.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00123.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00124.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00125.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00126.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00130.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00133.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00136.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00137.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00138.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00139.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00140.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00145.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00146.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00148.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00149.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00150.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00151.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00159.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00160.jpg: 3 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00161.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00162.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00163.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00164.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00186.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00240.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00241.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00242.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (1.1GB ram): 100%|██████████| 1680/1680 [00:14<00:00, 118.\u001b[0m\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/aidev/data/AI-Hub/ChildZoneCCTV/split/val/10_2020_11_21_15_4\u001b[0m\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/val/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00120.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/val/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00127.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/val/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00128.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/val/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00147.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/val/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00152.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.1GB ram): 100%|██████████| 210/210 [00:02<00:00, 104.60it\u001b[0m\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m3.13 anchors/target, 0.947 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mWARNING ⚠️ Extremely small objects found: 2045 of 32848 labels are <3 pixels in size\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 32848 points...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.7490: 100%|████\u001b[0m\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 4.33 anchors past thr\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=640, metric_all=0.286/0.749-mean/best, past_thr=0.473-mean: 6,5, 11,9, 6,20, 26,9, 12,29, 34,27, 113,60, 117,164, 256,234\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
            "Plotting labels to runs/train/exp7/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/exp7\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       0/99      2.12G     0.1239    0.06558    0.05018        246        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.901     0.0201     0.0118    0.00306\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       1/99      2.12G    0.09853     0.0678    0.02755        399        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.624      0.109     0.0905     0.0324\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       2/99      2.12G    0.09047    0.06302    0.01826        354        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.593      0.183     0.0849     0.0307\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       3/99      2.12G    0.08288    0.05822    0.01382        374        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.798      0.266      0.309      0.116\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       4/99      2.12G    0.07446    0.05785    0.01184        274        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.691       0.35      0.377      0.159\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       5/99      2.12G    0.07197     0.0589    0.01044        252        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.798      0.359      0.512      0.252\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       6/99      2.12G    0.06792     0.0555   0.009397        334        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.555      0.477      0.505      0.232\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       7/99      2.12G     0.0657    0.05615   0.008492        333        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.682      0.503      0.573      0.275\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       8/99      2.12G    0.06393    0.05342   0.007903        428        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.713      0.529      0.563      0.269\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       9/99      2.12G    0.06279    0.05237   0.007568        431        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.737      0.607      0.612      0.308\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      10/99      2.12G    0.06085    0.05225   0.007137        296        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.785      0.624      0.656      0.348\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      11/99      2.12G    0.05957    0.05141   0.006789        281        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.789       0.63      0.672      0.362\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      12/99      2.12G    0.05892    0.05059   0.006613        223        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.854      0.579      0.646      0.364\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      13/99      2.12G    0.05774     0.0501   0.006311        223        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946       0.83      0.598      0.657       0.36\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      14/99      2.12G    0.05694    0.05084   0.006227        324        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.761      0.635      0.658      0.379\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      15/99      2.12G    0.05671    0.05002   0.006119        415        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946       0.87      0.633        0.7      0.387\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      16/99      2.12G    0.05555    0.04789   0.005931        235        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.815      0.657      0.721      0.397\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      17/99      2.12G    0.05543    0.04914   0.005943        358        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.879      0.656      0.728      0.415\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      18/99      2.12G    0.05555    0.04898   0.005743        311        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.847      0.627      0.746      0.419\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      19/99      2.12G    0.05411     0.0468   0.005599        338        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.818      0.695      0.735      0.389\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      20/99      2.12G    0.05434    0.04872   0.005563        311        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.889      0.625      0.742      0.412\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      21/99      2.12G    0.05292    0.04578   0.005366        414        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.834      0.689      0.744      0.447\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      22/99      2.12G    0.05277    0.04775   0.005306        196        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.777      0.739      0.784      0.451\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      23/99      2.12G    0.05238    0.04559   0.005246        161        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.742      0.754      0.772       0.45\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      24/99      2.12G    0.05205    0.04607   0.005126        226        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.739      0.788       0.81      0.468\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      25/99      2.12G    0.05192    0.04581   0.005078        397        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.811      0.761      0.807      0.466\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      26/99      2.12G    0.05126    0.04508   0.004947        346        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.797      0.739      0.793      0.476\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      27/99      2.12G    0.05099    0.04553   0.004924        376        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.765      0.768      0.801      0.482\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      28/99      2.12G    0.05084    0.04568   0.004902        358        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.802      0.778      0.838      0.489\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      29/99      2.12G    0.05057    0.04572    0.00486        316        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946       0.82      0.784      0.838      0.536\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      30/99      2.12G    0.05005    0.04395    0.00483        367        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946       0.82      0.777      0.833      0.509\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      31/99      2.12G    0.04988    0.04373   0.004758        278        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.811      0.788      0.839      0.519\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      32/99      2.12G    0.04954    0.04431   0.004729        372        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.805       0.81      0.826      0.498\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      33/99      2.12G    0.04949    0.04326   0.004792        373        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.835      0.805      0.856      0.523\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      34/99      2.12G    0.04903    0.04335   0.004593        457        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.832      0.747      0.812      0.498\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      35/99      2.12G    0.04833    0.04303   0.004566        377        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.831      0.783      0.835       0.53\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      36/99      2.12G    0.04857    0.04369   0.004519        469        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946       0.86        0.8      0.852      0.526\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      37/99      2.12G    0.04844    0.04329   0.004429        394        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.841      0.794      0.836       0.54\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      38/99      2.12G    0.04785    0.04198    0.00446        443        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946       0.82      0.806      0.859      0.547\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      39/99      2.12G    0.04779    0.04251   0.004508        346        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.859      0.794      0.843       0.53\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      40/99      2.12G    0.04764    0.04179   0.004459        410        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.847      0.809      0.842      0.551\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      41/99      2.12G    0.04697    0.04205   0.004319        240        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.852      0.792      0.839       0.54\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      42/99      2.12G    0.04707    0.04124    0.00431        372        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.849      0.821      0.863      0.542\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      43/99      2.12G    0.04676    0.04221   0.004284        258        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.865      0.791      0.844      0.545\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      44/99      2.12G    0.04621    0.04081   0.004281        289        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.882      0.836      0.866      0.562\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      45/99      2.12G    0.04654    0.04102   0.004299        295        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.864      0.825      0.854      0.548\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      46/99      2.12G    0.04581    0.04065   0.004127        279        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946       0.86      0.809      0.856      0.559\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      47/99      2.12G    0.04567    0.03996   0.004186        362        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.854      0.806      0.846      0.551\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      48/99      2.12G    0.04564    0.04005   0.004109        161        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.869      0.836      0.865      0.566\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      49/99      2.12G    0.04554     0.0415   0.004179        307        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.867      0.821      0.862      0.561\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      50/99      2.12G    0.04503    0.03933   0.004096        296        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.892      0.832      0.865      0.571\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      51/99      2.12G    0.04505    0.04005    0.00407        235        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.889      0.826      0.874      0.561\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      52/99      2.12G    0.04475    0.04052    0.00404        155        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.866      0.838      0.862       0.58\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      53/99      2.12G    0.04459    0.03841   0.004056        263        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.882      0.843      0.871      0.585\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      54/99      2.12G    0.04454    0.03992   0.004052        403        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.871       0.81       0.85      0.576\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      55/99      2.12G    0.04426    0.03934   0.003989        360        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.913      0.825      0.868      0.582\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      56/99      2.12G    0.04472     0.0405   0.004087        391        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.909       0.85      0.882      0.579\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      57/99      2.12G    0.04402    0.03877   0.003929        316        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.904      0.832      0.867      0.581\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      58/99      2.12G    0.04419    0.03975   0.003954        215        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.895      0.839      0.877        0.6\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      59/99      2.12G    0.04391    0.03883   0.003879        363        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.904      0.824       0.87       0.59\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      60/99      2.12G     0.0436    0.03804   0.003832        241        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.892      0.829      0.873      0.601\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      61/99      2.12G    0.04352    0.03886   0.003897        268        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.909      0.829      0.879      0.581\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      62/99      2.12G    0.04392    0.03938   0.003859        322        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.928      0.843      0.886      0.609\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      63/99      2.12G    0.04319    0.03918   0.003787        390        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.919      0.832      0.881      0.602\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      64/99      2.12G    0.04331    0.03854   0.003779        354        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.902      0.862      0.893      0.613\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      65/99      2.12G    0.04219    0.03742   0.003731        297        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.933      0.844      0.883      0.592\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      66/99      2.12G    0.04322    0.03873   0.003771        300        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.906      0.841      0.879      0.614\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      67/99      2.12G    0.04269    0.03847   0.003782        282        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.895      0.843      0.878      0.593\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      68/99      2.12G    0.04267    0.03779   0.003751        307        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.909      0.853      0.892      0.614\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      69/99      2.12G     0.0417    0.03675   0.003714        296        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.934      0.841      0.885      0.604\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      70/99      2.12G    0.04197    0.03667   0.003747        428        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.926      0.851      0.885      0.611\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      71/99      2.12G    0.04206    0.03718   0.003703        361        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946        0.9      0.846      0.882      0.607\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      72/99      2.12G    0.04168    0.03658   0.003683        273        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.919      0.831      0.878      0.609\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      73/99      2.12G    0.04176    0.03755   0.003658        448        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.925      0.831      0.883      0.616\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      74/99      2.12G    0.04129    0.03571   0.003588        302        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946       0.92      0.825      0.879      0.607\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      75/99      2.12G    0.04171    0.03686   0.003647        249        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.931      0.848       0.89       0.62\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      76/99      2.12G    0.04117    0.03614   0.003648        224        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.925      0.859      0.881      0.618\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      77/99      2.12G    0.04126    0.03709   0.003544        264        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.929      0.844      0.893      0.633\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      78/99      2.12G    0.04082    0.03561   0.003568        395        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.925      0.872      0.902      0.636\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      79/99      2.12G    0.04034    0.03572    0.00354        232        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.915      0.863      0.883      0.624\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      80/99      2.12G    0.04053    0.03537   0.003525        176        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946       0.92      0.841      0.884      0.622\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      81/99      2.12G    0.04029     0.0357   0.003508        429        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.926      0.827      0.882       0.62\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      82/99      2.12G    0.04029    0.03516    0.00349        269        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.933      0.863       0.91       0.65\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      83/99      2.12G    0.04034    0.03511   0.003488        242        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.945      0.863      0.905      0.639\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      84/99      2.12G    0.04024    0.03532   0.003474        384        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.938      0.853       0.89      0.629\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      85/99      2.12G    0.04028     0.0352    0.00345        271        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.944      0.847      0.888      0.633\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      86/99      2.12G    0.04031    0.03514   0.003555        312        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.934      0.857      0.888      0.628\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      87/99      2.12G    0.03983    0.03452     0.0034        419        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.941      0.846      0.893      0.624\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      88/99      2.12G     0.0399    0.03431   0.003482        367        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.928      0.846      0.882      0.632\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      89/99      2.12G    0.03981    0.03462   0.003469        281        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.937      0.851      0.889      0.643\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      90/99      2.12G    0.03911    0.03368   0.003348        216        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.941      0.842      0.883      0.635\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      91/99      2.12G    0.03921    0.03341   0.003311        522        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.919      0.855      0.889      0.635\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      92/99      2.12G    0.03992    0.03523   0.003408        330        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.932      0.852      0.887      0.631\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      93/99      2.12G    0.03913    0.03353   0.003307        343        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.934      0.853      0.889      0.635\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      94/99      2.12G    0.03968    0.03529   0.003415        338        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946       0.95      0.852      0.888      0.639\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      95/99      2.12G     0.0391    0.03297   0.003391        369        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.939      0.872      0.906      0.655\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      96/99      2.12G    0.03954    0.03481   0.003387        241        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.945      0.851      0.888      0.639\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      97/99      2.12G    0.03906    0.03322   0.003379        304        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.951      0.852      0.892      0.641\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      98/99      2.12G    0.03919    0.03353   0.003337        371        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.945      0.854       0.89      0.644\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      99/99      2.12G     0.0395    0.03437   0.003402        257        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.938      0.854      0.892      0.648\n",
            "\n",
            "100 epochs completed in 0.287 hours.\n",
            "Optimizer stripped from runs/train/exp7/weights/last.pt, 14.5MB\n",
            "Optimizer stripped from runs/train/exp7/weights/best.pt, 14.5MB\n",
            "\n",
            "Validating runs/train/exp7/weights/best.pt...\n",
            "Fusing layers... \n",
            "train_cfg summary: 166 layers, 7078183 parameters, 0 gradients\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.942      0.861      0.906      0.655\n",
            "                person        210        671      0.911      0.778      0.852      0.555\n",
            "               vehicle        210       1894      0.953      0.865      0.953      0.747\n",
            "                 cycle        210         22          1      0.906       0.99      0.625\n",
            "                  kick        210        159      0.949      0.934       0.95      0.619\n",
            "                  face        210         44      0.856      0.795      0.818      0.405\n",
            "         license_plate        210        397      0.886        0.7      0.707      0.565\n",
            "         traffic_light        210        668      0.992      0.997      0.995      0.868\n",
            "             motorbike        210         91      0.993      0.912      0.983      0.859\n",
            "Results saved to \u001b[1mruns/train/exp7\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▂▅▅▆▆▆▇▇▇▇▇▇█▇█▇▇██████████████████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇██▇▇▇██████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▇▁▅▃▅▆▆▇▇▄▅▅▅▆▆▅▆▆▆▆▇▇▇▇▇▇▇█▇▇▇▇████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▂▄▅▆▆▆▆▆▇▇▇▇█▇█▇▇██████████████████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▅▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss █▇▇▆▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss █▆▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss █▄▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss █▆▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 █▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▃████▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ▃████▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 95\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.90597\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 0.65522\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.93924\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.87242\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.90607\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.65531\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.94244\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.86108\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.0395\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.0034\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.03437\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.03483\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.00304\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.03411\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.0003\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.0003\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.0003\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mlunar-festival-370\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/changsin/YOLOv5/runs/1p5eu6f8\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 337 media file(s), 1 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230204_151928-1p5eu6f8/logs\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "train_folder = DATA_ROOT + \"train\"\n",
        "val_folder = DATA_ROOT + \"val\"\n",
        "\n",
        "train_yolo(train_folder,\n",
        "           val_folder,\n",
        "           batch_size=10,\n",
        "           epochs=100,\n",
        "           weights_path=\"yolov5s.pt\")\n",
        "\n",
        "# !mv runs/train/exp /content/drive/MyDrive/data/Top15/runs/train/train15_0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Set train to /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train\n",
            "Set val to /home/aidev/data/AI-Hub/ChildZoneCCTV/split/val\n",
            "Set nc to 10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mchangsin\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=/home/aidev/data/AI-Hub/ChildZoneCCTV/split/train_cfg.yaml, data=/home/aidev/data/AI-Hub/ChildZoneCCTV/split/train_data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=100, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
            "YOLOv5 🚀 v7.0-72-g064365d8 Python-3.10.6 torch-1.13.1+cu117 CUDA:0 (NVIDIA GeForce RTX 3080 Ti, 12037MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "2023-02-04 15:42:21.031770: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-02-04 15:42:21.456482: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/aidev/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
            "2023-02-04 15:42:21.456527: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/aidev/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
            "2023-02-04 15:42:21.456534: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-02-04 15:42:22.660744: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-02-04 15:42:22.733798: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/aidev/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
            "2023-02-04 15:42:22.733821: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
            "2023-02-04 15:42:23.037623: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/aidev/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
            "2023-02-04 15:42:23.037664: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/aidev/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
            "2023-02-04 15:42:23.037670: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.13.9 is available!  To upgrade, please run:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.17\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/aidev/workspace/yolov5/wandb/run-20230204_154221-38wf7qjn\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mlunar-peony-371\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/changsin/YOLOv5\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/changsin/YOLOv5/runs/38wf7qjn\u001b[0m\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
            "  9                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     40455  models.yolo.Detect                      [10, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "train_cfg summary: 225 layers, 7087815 parameters, 7087815 gradients\n",
            "\n",
            "Transferred 308/361 items from yolov5s.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 59 weight(decay=0.0), 62 weight(decay=0.0005), 62 bias\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_21_\u001b[0m\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00091.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00095.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00096.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00097.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00098.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00099.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00100.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00101.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00102.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00103.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00104.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00105.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00106.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00107.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00108.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00110.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00111.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00112.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00113.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00114.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00115.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00117.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00118.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00119.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00121.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00122.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00123.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00124.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00125.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00126.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00130.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00133.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00136.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00137.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00138.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00139.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00140.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00145.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00146.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00148.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00149.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00150.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00151.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00159.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00160.jpg: 3 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00161.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00162.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00163.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00164.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00186.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00240.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00241.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00242.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (1.1GB ram): 100%|██████████| 1680/1680 [00:14<00:00, 119.\u001b[0m\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/aidev/data/AI-Hub/ChildZoneCCTV/split/val/10_2020_11_21_15_4\u001b[0m\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/val/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00120.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/val/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00127.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/val/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00128.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/val/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00147.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/val/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00152.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.1GB ram): 100%|██████████| 210/210 [00:02<00:00, 104.25it\u001b[0m\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m3.13 anchors/target, 0.947 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mWARNING ⚠️ Extremely small objects found: 2045 of 32848 labels are <3 pixels in size\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 32848 points...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.7490: 100%|████\u001b[0m\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 4.33 anchors past thr\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=640, metric_all=0.286/0.749-mean/best, past_thr=0.473-mean: 6,5, 11,9, 6,20, 26,9, 12,29, 34,27, 113,60, 117,164, 256,234\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
            "Plotting labels to runs/train/exp8/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/exp8\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       0/99      3.24G     0.1245    0.06579    0.05046        401        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.532     0.0134     0.0109    0.00361\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       1/99      3.62G    0.09929    0.06775    0.02788        407        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.382      0.148     0.0986     0.0355\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       2/99      3.62G    0.09066    0.06356    0.01862        436        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.715      0.182      0.171     0.0672\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       3/99      3.62G    0.08297    0.05868    0.01423        712        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.685      0.287       0.29      0.111\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       4/99      3.62G    0.07609    0.05744    0.01208        426        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.714      0.319      0.371      0.164\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       5/99      3.62G    0.07161    0.05847    0.01082        639        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946        0.6      0.469      0.444      0.198\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       6/99      3.62G    0.06836    0.05483    0.00969        444        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946       0.66      0.472      0.499      0.227\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       7/99      3.62G    0.06594    0.05563   0.008907        511        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.565      0.521      0.538      0.248\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       8/99      3.62G     0.0641    0.05297   0.008206        446        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946       0.62      0.551      0.578      0.283\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       9/99      3.62G    0.06316    0.05249   0.007808        557        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.682      0.576      0.601      0.301\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      10/99      3.62G    0.06148    0.05197   0.007308        509        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.734      0.605      0.628      0.321\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      11/99      3.62G    0.06034    0.05118   0.007069        347        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.784      0.612       0.65       0.33\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      12/99      3.62G    0.05909    0.05053   0.006691        539        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.807      0.605      0.652      0.336\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      13/99      3.62G    0.05844    0.05032   0.006507        475        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.794      0.643      0.672      0.386\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      14/99      3.62G    0.05776     0.0512    0.00637        636        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.847      0.644      0.705      0.388\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      15/99      3.62G    0.05694    0.04911   0.006224        677        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946       0.78      0.645      0.679      0.384\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      16/99      3.62G    0.05545    0.04799   0.005992        546        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.819      0.678      0.727      0.412\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      17/99      3.62G    0.05587    0.04928   0.005979        488        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.864      0.646      0.721      0.394\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      18/99      3.62G    0.05573    0.04874   0.005829        698        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.732      0.744      0.754      0.409\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      19/99      3.62G    0.05449    0.04692   0.005737        428        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946       0.84      0.675      0.733      0.424\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      20/99      3.62G    0.05403     0.0477   0.005538        303        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946       0.88      0.657      0.755      0.429\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      21/99      3.62G    0.05363    0.04562   0.005469        430        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.814      0.676      0.752      0.413\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      22/99      3.62G    0.05342    0.04794   0.005456        481        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.842      0.646      0.769      0.451\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      23/99      3.62G    0.05285    0.04566   0.005389        327        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946       0.86      0.665       0.78      0.464\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      24/99      3.62G    0.05227     0.0458   0.005287        528        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.827      0.702      0.783      0.464\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      25/99      3.62G    0.05201    0.04574   0.005204        472        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.801      0.757      0.793      0.463\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      26/99      3.62G    0.05195     0.0447   0.005144        393        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946       0.75      0.796      0.808      0.478\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      27/99      3.62G    0.05145    0.04527   0.004959        630        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.781      0.758      0.818      0.481\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      28/99      3.62G    0.05107    0.04585   0.004969        405        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.784      0.794      0.827      0.491\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      29/99      3.62G    0.05088    0.04584   0.004927        504        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946       0.81      0.786      0.843      0.507\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      30/99      3.62G     0.0503     0.0438   0.004807        499        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946       0.78      0.775      0.836      0.511\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      31/99      3.62G    0.05017    0.04382   0.004801        505        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.802      0.781      0.829      0.509\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      32/99      3.62G    0.04966    0.04437   0.004702        550        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.852      0.759      0.822      0.495\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      33/99      3.62G    0.04964    0.04346   0.004753        526        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.824      0.798      0.855      0.524\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      34/99      3.62G    0.04952    0.04276   0.004681        535        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.823      0.804      0.836      0.531\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      35/99      3.62G    0.04871    0.04132   0.004832        416        640:  "
          ]
        }
      ],
      "source": [
        "train_folder = DATA_ROOT + \"train\"\n",
        "val_folder = DATA_ROOT + \"val\"\n",
        "\n",
        "train_yolo(train_folder,\n",
        "           val_folder,\n",
        "           batch_size=16,\n",
        "           epochs=100,\n",
        "           weights_path=\"yolov5s.pt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ki3fla1eLG3g"
      },
      "source": [
        "# Validate with Test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLP0zOJQYERZ",
        "outputId": "acdc17c4-263c-4aaa-c286-be2da0885aa1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Set val to /content/drive/MyDrive/data/Top15/test_top15/top15_0\n",
            "\u001b[34m\u001b[1mval: \u001b[0mdata=/content/drive/MyDrive/data/Top15/validate.yaml, weights=['/content/drive/MyDrive/data/Top15/runs/train/train15_0/weights/best.pt'], batch_size=32, imgsz=640, conf_thres=0.5, iou_thres=0.6, task=val, device=, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=exp, exist_ok=False, half=False\n",
            "YOLOv5 🚀 v6.0-16-g6d9b99f torch 1.9.0+cu111 CUDA:0 (Tesla P100-PCIE-16GB, 16280.875MB)\n",
            "\n",
            "Fusing layers... \n",
            "Model Summary: 213 layers, 7085641 parameters, 0 gradients, 16.0 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/drive/MyDrive/data/Top15/test_top15/top15_0' images and labels...1000 found, 0 missing, 0 empty, 0 corrupted: 100% 1000/1000 [01:58<00:00,  8.43it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/drive/MyDrive/data/Top15/test_top15/top15_0.cache\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 32/32 [00:17<00:00,  1.81it/s]\n",
            "                 all       1000       4113       0.35     0.0733      0.208      0.152\n",
            "         alert@Brake       1000        340      0.971      0.194      0.583      0.452\n",
            "       alert@Coolant       1000        229          0          0          0          0\n",
            "      alert@Distance       1000        162      0.909     0.0617      0.487      0.368\n",
            "       alert@Parking       1000        468          1     0.0278      0.514      0.378\n",
            "     alert@Retaining       1000        140          0          0          0          0\n",
            "      alert@Seatbelt       1000        443      0.662      0.709      0.629      0.398\n",
            "      alert@Steering       1000        159          0          0          0          0\n",
            "         warning@ABS       1000        227          0          0          0          0\n",
            "       warning@Brake       1000        318      0.714     0.0472      0.379       0.29\n",
            "      warning@Engine       1000        469          0          0          0          0\n",
            "        warning@Fuel       1000        179          0          0          0          0\n",
            "     warning@Parking       1000        291          0          0          0          0\n",
            "warning@StabilityOff       1000        216          1     0.0602       0.53      0.394\n",
            " warning@StabilityOn       1000        234          0          0          0          0\n",
            "        warning@Tire       1000        238          0          0          0          0\n",
            "Speed: 0.1ms pre-process, 3.3ms inference, 0.8ms NMS per image at shape (32, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/val/exp3\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "def val_yolo(val_data_path, conf=0.5, weights_path=None):\n",
        "  data_yaml = DATA_ROOT + \"validate.yaml\"\n",
        "  create_yaml(DATA_ROOT + \"validate_temp.yaml\", data_yaml, dict({\"val\": val_data_path}))\n",
        "\n",
        "  if weights_path is None:\n",
        "    weights_path = \"yolov5s.pt\"\n",
        "\n",
        "  !python val.py --weights $weights_path --img 640 --conf $conf --data $data_yaml\n",
        "\n",
        "val_yolo(\"/content/drive/MyDrive/data/Top15/test_top15/top15_0\", conf=0.5, weights_path=\"/content/drive/MyDrive/data/Top15/runs/train/train15_0/weights/best.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "2iKO_l6avgM1"
      },
      "outputs": [],
      "source": [
        "val_yolo(\"/content/drive/MyDrive/data/Top15/test_top15/top15_0\", conf=0.5, weights_path=\"/content/drive/MyDrive/data/Top15/runs/train/train15_0/weights/best.pt\")\n",
        "!mv runs/val/exp /content/drive/MyDrive/data/Top15/runs/test/test15_0"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyPFeyejc/tGVDijwq+gQwMP",
      "include_colab_link": true,
      "machine_shape": "hm",
      "name": "train_dashboard_top15.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

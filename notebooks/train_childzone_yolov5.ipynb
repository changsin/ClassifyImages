{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/changsin/ClassifyImages/blob/main/notebooks/train_dashboard_top15.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "l3IR2E-4bPaO"
      },
      "source": [
        "# ChildZone Data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmr3ahqma9uk"
      },
      "source": [
        "# Setup\n",
        "Install requirements and prepare the dataset for training.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPDC6ckKkr1l",
        "outputId": "dd29a929-71ed-4e77-e79f-fa718a3deafd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7fNDvNWOWvpl"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output \n",
        "\n",
        "!pip install pafy\n",
        "!pip install -q youtube-dl\n",
        "\n",
        "!pip install yolov5\n",
        "\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Sp8S964yARl",
        "outputId": "d72a589e-2b3e-47eb-9372-ccebe8370387"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setup complete. Using torch 1.9.0+cu111 (Tesla P100-PCIE-16GB)\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ultralytics/yolov5  # clone repo\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt  # install dependencies\n",
        "\n",
        "import torch\n",
        "from IPython.display import Image, clear_output  # to display images\n",
        "\n",
        "clear_output()\n",
        "print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccpQvXLlatKP"
      },
      "source": [
        "Download pretrained yolov5 model\n",
        "Choose one of the pretrained models from https://github.com/ultralytics/yolov5#inference\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5pTcJ1fyG5T",
        "outputId": "69a60b5d-abfc-49cc-8368-862baa7578b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2021-10-16 07:51:43--  https://github.com/ultralytics/yolov5/releases/download/v5.0/yolov5s.pt\n",
            "Resolving github.com (github.com)... 192.30.255.112\n",
            "Connecting to github.com (github.com)|192.30.255.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-releases.githubusercontent.com/264818686/56dd3480-9af3-11eb-9c92-3ecd167961dc?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20211016%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20211016T075143Z&X-Amz-Expires=300&X-Amz-Signature=d0896974b764f558700d3af775b495cdb6afb8b78e64ba99cc91ba7327ac3102&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=264818686&response-content-disposition=attachment%3B%20filename%3Dyolov5s.pt&response-content-type=application%2Foctet-stream [following]\n",
            "--2021-10-16 07:51:43--  https://github-releases.githubusercontent.com/264818686/56dd3480-9af3-11eb-9c92-3ecd167961dc?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20211016%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20211016T075143Z&X-Amz-Expires=300&X-Amz-Signature=d0896974b764f558700d3af775b495cdb6afb8b78e64ba99cc91ba7327ac3102&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=264818686&response-content-disposition=attachment%3B%20filename%3Dyolov5s.pt&response-content-type=application%2Foctet-stream\n",
            "Resolving github-releases.githubusercontent.com (github-releases.githubusercontent.com)... 185.199.108.154, 185.199.111.154, 185.199.109.154, ...\n",
            "Connecting to github-releases.githubusercontent.com (github-releases.githubusercontent.com)|185.199.108.154|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14795158 (14M) [application/octet-stream]\n",
            "Saving to: ‘yolov5s.pt’\n",
            "\n",
            "yolov5s.pt          100%[===================>]  14.11M  76.4MB/s    in 0.2s    \n",
            "\n",
            "2021-10-16 07:51:43 (76.4 MB/s) - ‘yolov5s.pt’ saved [14795158/14795158]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/ultralytics/yolov5/releases/download/v5.0/yolov5s.pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/aidev/data/AI-Hub/ChildZoneCCTV/split\n",
            "/home/aidev/data/AI-Hub/ChildZoneCCTV/split\n",
            "total 20\n",
            "drwxrwxr-x 5 aidev aidev 4096  2월  3 12:51 .\n",
            "drwxrwxr-x 3 aidev aidev 4096  2월  3 12:07 ..\n",
            "drwxrwxr-x 9 aidev aidev 4096  2월  3 12:11 test\n",
            "drwxrwxr-x 9 aidev aidev 4096  2월  3 12:45 train\n",
            "drwxrwxr-x 9 aidev aidev 4096  2월  3 12:55 val\n"
          ]
        }
      ],
      "source": [
        "%cd /home/aidev/data/AI-Hub/ChildZoneCCTV/split\n",
        "!pwd\n",
        "!ls -al"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1SYBEUwDcFwq"
      },
      "outputs": [],
      "source": [
        "DATA_ROOT = \"/home/aidev/data/AI-Hub/ChildZoneCCTV/split/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qdNGi08turU"
      },
      "source": [
        "## Copy files (One time)\n",
        "\n",
        "To make val and test folders flat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JS8FNRNBm-z2"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "\n",
        "def glob_files(folder, file_type='*'):\n",
        "    search_string = os.path.join(folder, file_type)\n",
        "    files = glob.glob(search_string)\n",
        "\n",
        "    print('Searching ', search_string)\n",
        "    paths = []\n",
        "    for f in files:\n",
        "      if os.path.isdir(f):\n",
        "        sub_paths = glob_files(f + '/')\n",
        "        paths += sub_paths\n",
        "      else:\n",
        "        paths.append(f)\n",
        "\n",
        "    # We sort the images in alphabetical order to match them\n",
        "    #  to the annotation files\n",
        "    paths.sort()\n",
        "\n",
        "    return paths\n",
        "\n",
        "\n",
        "def glob_folders(folder, file_type='*'):\n",
        "    search_string = os.path.join(folder, file_type)\n",
        "    files = glob.glob(search_string)\n",
        "\n",
        "    print('Searching ', search_string)\n",
        "    paths = []\n",
        "    for f in files:\n",
        "      if os.path.isdir(f):\n",
        "        paths.append(f)\n",
        "\n",
        "    # We sort the images in alphabetical order to match them\n",
        "    #  to the annotation files\n",
        "    paths.sort()\n",
        "\n",
        "    return paths\n",
        "\n",
        "def split_val_files(parent_folder, folder_from, folder_to):\n",
        "  folder_to = os.path.join(parent_folder, folder_to)\n",
        "  if not os.path.exists(folder_to):\n",
        "    print(\"Creating folder to \", folder_to)\n",
        "    os.mkdir(folder_to)\n",
        "\n",
        "  sub_folders = glob_folders(folder_from)\n",
        "  copied_count = 0\n",
        "\n",
        "  for sub_id, sub_folder in enumerate(sub_folders):\n",
        "    files = glob_files(sub_folder)\n",
        "  \n",
        "    # end_id = int(len(files) * 0.2)\n",
        "    end_id = len(files)\n",
        "    print(\"Copying {} files\".format(end_id))\n",
        "\n",
        "    sub_folder_to = os.path.join(folder_to, \"{}_{}\"\n",
        "      .format(os.path.basename(folder_to), sub_id))\n",
        "    if not os.path.exists(sub_folder_to):\n",
        "      print(\"Creating folder to \", sub_folder_to)\n",
        "      os.mkdir(sub_folder_to)\n",
        "\n",
        "    for id in range(end_id):\n",
        "      file_from = files[id]\n",
        "      file_to = os.path.join(sub_folder_to, os.path.basename(file_from))\n",
        "\n",
        "      if os.path.exists(file_to):\n",
        "        print(\"ERROR: target {} already exists\".format(file_to))\n",
        "        print(\"Skipping\")\n",
        "        continue\n",
        "        # exit(-1)\n",
        "\n",
        "      else:\n",
        "        print(file_from, file_to)\n",
        "        shutil.copy(file_from, file_to)\n",
        "    copied_count += end_id\n",
        "\n",
        "  print(\"Copied \", copied_count)\n",
        "\n",
        "\n",
        "def copy_data_files(folder_from, folder_to):\n",
        "  sub_folders = glob_folders(folder_from)\n",
        "  copied_count = 0\n",
        "\n",
        "  for sub_folder in sub_folders:\n",
        "    files = glob_files(sub_folder)\n",
        "\n",
        "    for file_from in files:\n",
        "      if os.path.exists(file_from):\n",
        "          file_to = os.path.join(folder_to, os.path.basename(file_from))\n",
        "\n",
        "          if os.path.exists(file_to):\n",
        "            print(\"ERROR: target {} already exists\".format(file_to))\n",
        "            print(\"Skipping\")\n",
        "            continue\n",
        "            # exit(-1)\n",
        "\n",
        "          shutil.copy(file_from, file_to)\n",
        "          copied_count += 1\n",
        "\n",
        "  print(\"Copied \", copied_count)\n",
        "\n",
        "split_val_files(\"/content/drive/MyDrive/data/Top15\",\n",
        "                \"/content/drive/MyDrive/data/Top15/train_a_seatbelt\",\n",
        "                # \"/content/drive/MyDrive/data/Top15/val_a_seatbelt\")\n",
        "                \"/content/drive/MyDrive/data/Top15/train_a_seatbelt1\")\n",
        "# copy_data_files(DATA_ROOT + \"test_raw\", DATA_ROOT + \"test\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wD1pTl7FuAVc"
      },
      "source": [
        "# Train Dashboard Labels Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Ao-CwRDAt5Lt"
      },
      "outputs": [],
      "source": [
        "import yaml\n",
        "import subprocess\n",
        "\n",
        "def create_yaml(yaml_from, yaml_to, to_set):\n",
        "  with open(yaml_from) as fr:\n",
        "      train_config = yaml.safe_load(fr)\n",
        "\n",
        "      for key, value in to_set.items():\n",
        "        print(\"Set {} to {}\".format(key, value))\n",
        "        train_config[key] = value\n",
        "\n",
        "      with open(yaml_to, 'w') as fw:\n",
        "        fw.write(str(train_config))\n",
        "\n",
        "def launch_process(command):\n",
        "  print(command)\n",
        "  process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE)\n",
        "  process.wait()\n",
        "  for line in process.stdout:\n",
        "      print(str(line))\n",
        "\n",
        "  print(process.stderr)\n",
        "\n",
        "  return process.stdout, process.returncode\n",
        "\n",
        "def to_file(file_to, data):\n",
        "  with open(file_to, 'w') as f:\n",
        "    f.write(str(data))\n",
        "\n",
        "def train_yolo(train_data_path, val_data_path, batch_size=10, epochs=100, weights_path=None):\n",
        "  data_yaml = DATA_ROOT + \"train_data.yaml\"\n",
        "  to_set = dict({\"train\": train_data_path, \"val\": val_data_path})\n",
        "  create_yaml(\"/home/aidev/workspace/ClassifyImages/data/configs/yolov5_child_zone.yaml\", data_yaml, to_set)\n",
        "\n",
        "  cfg_yaml = DATA_ROOT + \"train_cfg.yaml\"\n",
        "  create_yaml(\"/home/aidev/workspace/ClassifyImages/data/configs/train_cfg_child_zone.yaml\", cfg_yaml, dict({\"nc\": 10}))\n",
        "\n",
        "  if weights_path is None:\n",
        "    weights_path = \"yolov5s.pt\"\n",
        "\n",
        "  !echo train.py --img 640 --batch $batch_size --epochs $epochs --data $data_yaml --cfg $cfg_yaml --weights $weights_path --cache\n",
        "  !python3 train.py --img 640 --batch $batch_size --epochs $epochs --data $data_yaml --cfg $cfg_yaml --weights $weights_path --cache\n",
        "\n",
        "# !rm -rf runs/train\n",
        "# train_yolo(DATA_ROOT+\"/train\", DATA_ROOT+\"/val\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94T2yMxwGen3",
        "outputId": "70618e34-b203-4645-d707-73c5ad22d905"
      },
      "outputs": [],
      "source": [
        "!ls -Q $train_folder | head -10 | xargs -I {} echo {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%cd /home/aidev/workspace/yolov5\n",
        "!pwd\n",
        "!ls -al"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Train"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Install Weights & Biases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: wandb in /home/aidev/.local/lib/python3.10/site-packages (0.12.17)\n",
            "Requirement already satisfied: protobuf<4.0dev,>=3.12.0 in /home/aidev/.local/lib/python3.10/site-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: GitPython>=1.0.0 in /home/aidev/.local/lib/python3.10/site-packages (from wandb) (3.1.30)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /home/aidev/.local/lib/python3.10/site-packages (from wandb) (2.8.2)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /home/aidev/.local/lib/python3.10/site-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from wandb) (59.6.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /home/aidev/.local/lib/python3.10/site-packages (from wandb) (5.9.4)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /home/aidev/.local/lib/python3.10/site-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: shortuuid>=0.5.0 in /home/aidev/.local/lib/python3.10/site-packages (from wandb) (1.0.11)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /home/aidev/.local/lib/python3.10/site-packages (from wandb) (1.14.0)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/lib/python3/dist-packages (from wandb) (1.16.0)\n",
            "Requirement already satisfied: PyYAML in /usr/lib/python3/dist-packages (from wandb) (5.4.1)\n",
            "Requirement already satisfied: pathtools in /home/aidev/.local/lib/python3.10/site-packages (from wandb) (0.1.2)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /home/aidev/.local/lib/python3.10/site-packages (from wandb) (8.0.4)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/lib/python3/dist-packages (from wandb) (2.25.1)\n",
            "Requirement already satisfied: setproctitle in /home/aidev/.local/lib/python3.10/site-packages (from wandb) (1.3.2)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/aidev/.local/lib/python3.10/site-packages (from GitPython>=1.0.0->wandb) (4.0.10)\n",
            "Requirement already satisfied: urllib3>=1.26.11 in /home/aidev/.local/lib/python3.10/site-packages (from sentry-sdk>=1.0.0->wandb) (1.26.14)\n",
            "Requirement already satisfied: certifi in /usr/lib/python3/dist-packages (from sentry-sdk>=1.0.0->wandb) (2020.6.20)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /home/aidev/.local/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install wandb"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Really Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VErMf-CIlVlG",
        "outputId": "cd5ca339-8ddb-4e4d-fd21-4f51db7ff3c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Set train to /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train\n",
            "Set val to /home/aidev/data/AI-Hub/ChildZoneCCTV/split/val\n",
            "Set nc to 10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mchangsin\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=/home/aidev/data/AI-Hub/ChildZoneCCTV/split/train_cfg.yaml, data=/home/aidev/data/AI-Hub/ChildZoneCCTV/split/train_data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=100, batch_size=10, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
            "YOLOv5 🚀 v7.0-72-g064365d8 Python-3.10.6 torch-1.13.1+cu117 CUDA:0 (NVIDIA GeForce RTX 3080 Ti, 12037MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "2023-02-04 15:19:28.090716: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-02-04 15:19:28.512812: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/aidev/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
            "2023-02-04 15:19:28.512860: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/aidev/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
            "2023-02-04 15:19:28.512867: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-02-04 15:19:30.022877: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-02-04 15:19:30.097182: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/aidev/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
            "2023-02-04 15:19:30.097203: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
            "2023-02-04 15:19:30.403645: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/aidev/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
            "2023-02-04 15:19:30.403688: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/aidev/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
            "2023-02-04 15:19:30.403694: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.13.9 is available!  To upgrade, please run:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.17\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/aidev/workspace/yolov5/wandb/run-20230204_151928-1p5eu6f8\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mlunar-festival-370\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/changsin/YOLOv5\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/changsin/YOLOv5/runs/1p5eu6f8\u001b[0m\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
            "  9                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     40455  models.yolo.Detect                      [10, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "train_cfg summary: 225 layers, 7087815 parameters, 7087815 gradients\n",
            "\n",
            "Transferred 308/361 items from yolov5s.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 59 weight(decay=0.0), 62 weight(decay=0.00046875), 62 bias\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_21_\u001b[0m\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00091.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00095.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00096.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00097.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00098.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00099.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00100.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00101.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00102.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00103.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00104.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00105.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00106.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00107.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00108.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00110.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00111.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00112.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00113.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00114.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00115.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00117.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00118.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00119.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00121.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00122.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00123.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00124.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00125.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00126.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00130.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00133.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00136.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00137.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00138.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00139.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00140.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00145.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00146.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00148.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00149.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00150.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00151.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00159.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00160.jpg: 3 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00161.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00162.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00163.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00164.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00186.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00240.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00241.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00242.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (1.1GB ram): 100%|██████████| 1680/1680 [00:14<00:00, 118.\u001b[0m\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/aidev/data/AI-Hub/ChildZoneCCTV/split/val/10_2020_11_21_15_4\u001b[0m\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/val/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00120.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/val/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00127.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/val/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00128.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/val/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00147.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/val/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00152.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.1GB ram): 100%|██████████| 210/210 [00:02<00:00, 104.60it\u001b[0m\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m3.13 anchors/target, 0.947 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mWARNING ⚠️ Extremely small objects found: 2045 of 32848 labels are <3 pixels in size\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 32848 points...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.7490: 100%|████\u001b[0m\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 4.33 anchors past thr\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=640, metric_all=0.286/0.749-mean/best, past_thr=0.473-mean: 6,5, 11,9, 6,20, 26,9, 12,29, 34,27, 113,60, 117,164, 256,234\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
            "Plotting labels to runs/train/exp7/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/exp7\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       0/99      2.12G     0.1239    0.06558    0.05018        246        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.901     0.0201     0.0118    0.00306\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       1/99      2.12G    0.09853     0.0678    0.02755        399        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.624      0.109     0.0905     0.0324\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       2/99      2.12G    0.09047    0.06302    0.01826        354        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.593      0.183     0.0849     0.0307\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       3/99      2.12G    0.08288    0.05822    0.01382        374        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.798      0.266      0.309      0.116\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       4/99      2.12G    0.07446    0.05785    0.01184        274        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.691       0.35      0.377      0.159\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       5/99      2.12G    0.07197     0.0589    0.01044        252        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.798      0.359      0.512      0.252\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       6/99      2.12G    0.06792     0.0555   0.009397        334        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.555      0.477      0.505      0.232\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       7/99      2.12G     0.0657    0.05615   0.008492        333        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.682      0.503      0.573      0.275\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       8/99      2.12G    0.06393    0.05342   0.007903        428        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.713      0.529      0.563      0.269\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       9/99      2.12G    0.06279    0.05237   0.007568        431        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.737      0.607      0.612      0.308\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      10/99      2.12G    0.06085    0.05225   0.007137        296        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.785      0.624      0.656      0.348\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      11/99      2.12G    0.05957    0.05141   0.006789        281        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.789       0.63      0.672      0.362\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      12/99      2.12G    0.05892    0.05059   0.006613        223        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.854      0.579      0.646      0.364\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      13/99      2.12G    0.05774     0.0501   0.006311        223        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946       0.83      0.598      0.657       0.36\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      14/99      2.12G    0.05694    0.05084   0.006227        324        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.761      0.635      0.658      0.379\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      15/99      2.12G    0.05671    0.05002   0.006119        415        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946       0.87      0.633        0.7      0.387\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      16/99      2.12G    0.05555    0.04789   0.005931        235        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.815      0.657      0.721      0.397\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      17/99      2.12G    0.05543    0.04914   0.005943        358        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.879      0.656      0.728      0.415\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      18/99      2.12G    0.05555    0.04898   0.005743        311        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.847      0.627      0.746      0.419\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      19/99      2.12G    0.05411     0.0468   0.005599        338        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.818      0.695      0.735      0.389\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      20/99      2.12G    0.05434    0.04872   0.005563        311        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.889      0.625      0.742      0.412\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      21/99      2.12G    0.05292    0.04578   0.005366        414        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.834      0.689      0.744      0.447\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      22/99      2.12G    0.05277    0.04775   0.005306        196        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.777      0.739      0.784      0.451\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      23/99      2.12G    0.05238    0.04559   0.005246        161        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.742      0.754      0.772       0.45\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      24/99      2.12G    0.05205    0.04607   0.005126        226        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.739      0.788       0.81      0.468\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      25/99      2.12G    0.05192    0.04581   0.005078        397        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.811      0.761      0.807      0.466\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      26/99      2.12G    0.05126    0.04508   0.004947        346        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.797      0.739      0.793      0.476\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      27/99      2.12G    0.05099    0.04553   0.004924        376        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.765      0.768      0.801      0.482\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      28/99      2.12G    0.05084    0.04568   0.004902        358        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.802      0.778      0.838      0.489\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      29/99      2.12G    0.05057    0.04572    0.00486        316        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946       0.82      0.784      0.838      0.536\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      30/99      2.12G    0.05005    0.04395    0.00483        367        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946       0.82      0.777      0.833      0.509\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      31/99      2.12G    0.04988    0.04373   0.004758        278        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.811      0.788      0.839      0.519\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      32/99      2.12G    0.04954    0.04431   0.004729        372        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.805       0.81      0.826      0.498\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      33/99      2.12G    0.04949    0.04326   0.004792        373        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.835      0.805      0.856      0.523\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      34/99      2.12G    0.04903    0.04335   0.004593        457        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.832      0.747      0.812      0.498\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      35/99      2.12G    0.04833    0.04303   0.004566        377        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.831      0.783      0.835       0.53\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      36/99      2.12G    0.04857    0.04369   0.004519        469        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946       0.86        0.8      0.852      0.526\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      37/99      2.12G    0.04844    0.04329   0.004429        394        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.841      0.794      0.836       0.54\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      38/99      2.12G    0.04785    0.04198    0.00446        443        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946       0.82      0.806      0.859      0.547\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      39/99      2.12G    0.04779    0.04251   0.004508        346        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.859      0.794      0.843       0.53\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      40/99      2.12G    0.04764    0.04179   0.004459        410        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.847      0.809      0.842      0.551\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      41/99      2.12G    0.04697    0.04205   0.004319        240        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.852      0.792      0.839       0.54\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      42/99      2.12G    0.04707    0.04124    0.00431        372        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.849      0.821      0.863      0.542\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      43/99      2.12G    0.04676    0.04221   0.004284        258        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.865      0.791      0.844      0.545\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      44/99      2.12G    0.04621    0.04081   0.004281        289        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.882      0.836      0.866      0.562\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      45/99      2.12G    0.04654    0.04102   0.004299        295        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.864      0.825      0.854      0.548\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      46/99      2.12G    0.04581    0.04065   0.004127        279        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946       0.86      0.809      0.856      0.559\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      47/99      2.12G    0.04567    0.03996   0.004186        362        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.854      0.806      0.846      0.551\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      48/99      2.12G    0.04564    0.04005   0.004109        161        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.869      0.836      0.865      0.566\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      49/99      2.12G    0.04554     0.0415   0.004179        307        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.867      0.821      0.862      0.561\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      50/99      2.12G    0.04503    0.03933   0.004096        296        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.892      0.832      0.865      0.571\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      51/99      2.12G    0.04505    0.04005    0.00407        235        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.889      0.826      0.874      0.561\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      52/99      2.12G    0.04475    0.04052    0.00404        155        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.866      0.838      0.862       0.58\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      53/99      2.12G    0.04459    0.03841   0.004056        263        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.882      0.843      0.871      0.585\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      54/99      2.12G    0.04454    0.03992   0.004052        403        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.871       0.81       0.85      0.576\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      55/99      2.12G    0.04426    0.03934   0.003989        360        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.913      0.825      0.868      0.582\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      56/99      2.12G    0.04472     0.0405   0.004087        391        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.909       0.85      0.882      0.579\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      57/99      2.12G    0.04402    0.03877   0.003929        316        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.904      0.832      0.867      0.581\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      58/99      2.12G    0.04419    0.03975   0.003954        215        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.895      0.839      0.877        0.6\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      59/99      2.12G    0.04391    0.03883   0.003879        363        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.904      0.824       0.87       0.59\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      60/99      2.12G     0.0436    0.03804   0.003832        241        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.892      0.829      0.873      0.601\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      61/99      2.12G    0.04352    0.03886   0.003897        268        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.909      0.829      0.879      0.581\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      62/99      2.12G    0.04392    0.03938   0.003859        322        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.928      0.843      0.886      0.609\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      63/99      2.12G    0.04319    0.03918   0.003787        390        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.919      0.832      0.881      0.602\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      64/99      2.12G    0.04331    0.03854   0.003779        354        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.902      0.862      0.893      0.613\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      65/99      2.12G    0.04219    0.03742   0.003731        297        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.933      0.844      0.883      0.592\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      66/99      2.12G    0.04322    0.03873   0.003771        300        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.906      0.841      0.879      0.614\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      67/99      2.12G    0.04269    0.03847   0.003782        282        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.895      0.843      0.878      0.593\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      68/99      2.12G    0.04267    0.03779   0.003751        307        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.909      0.853      0.892      0.614\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      69/99      2.12G     0.0417    0.03675   0.003714        296        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.934      0.841      0.885      0.604\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      70/99      2.12G    0.04197    0.03667   0.003747        428        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.926      0.851      0.885      0.611\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      71/99      2.12G    0.04206    0.03718   0.003703        361        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946        0.9      0.846      0.882      0.607\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      72/99      2.12G    0.04168    0.03658   0.003683        273        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.919      0.831      0.878      0.609\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      73/99      2.12G    0.04176    0.03755   0.003658        448        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.925      0.831      0.883      0.616\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      74/99      2.12G    0.04129    0.03571   0.003588        302        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946       0.92      0.825      0.879      0.607\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      75/99      2.12G    0.04171    0.03686   0.003647        249        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.931      0.848       0.89       0.62\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      76/99      2.12G    0.04117    0.03614   0.003648        224        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.925      0.859      0.881      0.618\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      77/99      2.12G    0.04126    0.03709   0.003544        264        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.929      0.844      0.893      0.633\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      78/99      2.12G    0.04082    0.03561   0.003568        395        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.925      0.872      0.902      0.636\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      79/99      2.12G    0.04034    0.03572    0.00354        232        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.915      0.863      0.883      0.624\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      80/99      2.12G    0.04053    0.03537   0.003525        176        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946       0.92      0.841      0.884      0.622\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      81/99      2.12G    0.04029     0.0357   0.003508        429        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.926      0.827      0.882       0.62\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      82/99      2.12G    0.04029    0.03516    0.00349        269        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.933      0.863       0.91       0.65\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      83/99      2.12G    0.04034    0.03511   0.003488        242        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.945      0.863      0.905      0.639\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      84/99      2.12G    0.04024    0.03532   0.003474        384        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.938      0.853       0.89      0.629\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      85/99      2.12G    0.04028     0.0352    0.00345        271        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.944      0.847      0.888      0.633\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      86/99      2.12G    0.04031    0.03514   0.003555        312        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.934      0.857      0.888      0.628\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      87/99      2.12G    0.03983    0.03452     0.0034        419        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.941      0.846      0.893      0.624\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      88/99      2.12G     0.0399    0.03431   0.003482        367        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.928      0.846      0.882      0.632\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      89/99      2.12G    0.03981    0.03462   0.003469        281        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.937      0.851      0.889      0.643\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      90/99      2.12G    0.03911    0.03368   0.003348        216        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.941      0.842      0.883      0.635\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      91/99      2.12G    0.03921    0.03341   0.003311        522        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.919      0.855      0.889      0.635\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      92/99      2.12G    0.03992    0.03523   0.003408        330        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.932      0.852      0.887      0.631\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      93/99      2.12G    0.03913    0.03353   0.003307        343        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.934      0.853      0.889      0.635\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      94/99      2.12G    0.03968    0.03529   0.003415        338        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946       0.95      0.852      0.888      0.639\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      95/99      2.12G     0.0391    0.03297   0.003391        369        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.939      0.872      0.906      0.655\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      96/99      2.12G    0.03954    0.03481   0.003387        241        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.945      0.851      0.888      0.639\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      97/99      2.12G    0.03906    0.03322   0.003379        304        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.951      0.852      0.892      0.641\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      98/99      2.12G    0.03919    0.03353   0.003337        371        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.945      0.854       0.89      0.644\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      99/99      2.12G     0.0395    0.03437   0.003402        257        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.938      0.854      0.892      0.648\n",
            "\n",
            "100 epochs completed in 0.287 hours.\n",
            "Optimizer stripped from runs/train/exp7/weights/last.pt, 14.5MB\n",
            "Optimizer stripped from runs/train/exp7/weights/best.pt, 14.5MB\n",
            "\n",
            "Validating runs/train/exp7/weights/best.pt...\n",
            "Fusing layers... \n",
            "train_cfg summary: 166 layers, 7078183 parameters, 0 gradients\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.942      0.861      0.906      0.655\n",
            "                person        210        671      0.911      0.778      0.852      0.555\n",
            "               vehicle        210       1894      0.953      0.865      0.953      0.747\n",
            "                 cycle        210         22          1      0.906       0.99      0.625\n",
            "                  kick        210        159      0.949      0.934       0.95      0.619\n",
            "                  face        210         44      0.856      0.795      0.818      0.405\n",
            "         license_plate        210        397      0.886        0.7      0.707      0.565\n",
            "         traffic_light        210        668      0.992      0.997      0.995      0.868\n",
            "             motorbike        210         91      0.993      0.912      0.983      0.859\n",
            "Results saved to \u001b[1mruns/train/exp7\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▂▅▅▆▆▆▇▇▇▇▇▇█▇█▇▇██████████████████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇██▇▇▇██████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▇▁▅▃▅▆▆▇▇▄▅▅▅▆▆▅▆▆▆▆▇▇▇▇▇▇▇█▇▇▇▇████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▂▄▅▆▆▆▆▆▇▇▇▇█▇█▇▇██████████████████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▅▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss █▇▇▆▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss █▆▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss █▄▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss █▆▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 █▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▃████▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ▃████▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 95\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.90597\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 0.65522\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.93924\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.87242\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.90607\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.65531\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.94244\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.86108\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.0395\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.0034\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.03437\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.03483\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.00304\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.03411\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.0003\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.0003\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.0003\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mlunar-festival-370\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/changsin/YOLOv5/runs/1p5eu6f8\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 337 media file(s), 1 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230204_151928-1p5eu6f8/logs\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "train_folder = DATA_ROOT + \"train\"\n",
        "val_folder = DATA_ROOT + \"val\"\n",
        "\n",
        "train_yolo(train_folder,\n",
        "           val_folder,\n",
        "           batch_size=10,\n",
        "           epochs=100,\n",
        "           weights_path=\"yolov5s.pt\")\n",
        "\n",
        "# !mv runs/train/exp /content/drive/MyDrive/data/Top15/runs/train/train15_0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Set train to /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train\n",
            "Set val to /home/aidev/data/AI-Hub/ChildZoneCCTV/split/val\n",
            "Set nc to 10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mchangsin\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=/home/aidev/data/AI-Hub/ChildZoneCCTV/split/train_cfg.yaml, data=/home/aidev/data/AI-Hub/ChildZoneCCTV/split/train_data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=100, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
            "YOLOv5 🚀 v7.0-72-g064365d8 Python-3.10.6 torch-1.13.1+cu117 CUDA:0 (NVIDIA GeForce RTX 3080 Ti, 12037MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "2023-02-04 15:42:21.031770: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-02-04 15:42:21.456482: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/aidev/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
            "2023-02-04 15:42:21.456527: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/aidev/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
            "2023-02-04 15:42:21.456534: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-02-04 15:42:22.660744: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-02-04 15:42:22.733798: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/aidev/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
            "2023-02-04 15:42:22.733821: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
            "2023-02-04 15:42:23.037623: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/aidev/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
            "2023-02-04 15:42:23.037664: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/aidev/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
            "2023-02-04 15:42:23.037670: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.13.9 is available!  To upgrade, please run:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.17\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/aidev/workspace/yolov5/wandb/run-20230204_154221-38wf7qjn\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mlunar-peony-371\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/changsin/YOLOv5\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/changsin/YOLOv5/runs/38wf7qjn\u001b[0m\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
            "  9                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     40455  models.yolo.Detect                      [10, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "train_cfg summary: 225 layers, 7087815 parameters, 7087815 gradients\n",
            "\n",
            "Transferred 308/361 items from yolov5s.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 59 weight(decay=0.0), 62 weight(decay=0.0005), 62 bias\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_21_\u001b[0m\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00091.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00095.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00096.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00097.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00098.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00099.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00100.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00101.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00102.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00103.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00104.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00105.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00106.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00107.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00108.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00110.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00111.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00112.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00113.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00114.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00115.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00117.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00118.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00119.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00121.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00122.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00123.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00124.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00125.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00126.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00130.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00133.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00136.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00137.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00138.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00139.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00140.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00145.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00146.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00148.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00149.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00150.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00151.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00159.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00160.jpg: 3 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00161.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00162.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00163.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00164.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00186.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00240.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00241.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00242.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (1.1GB ram): 100%|██████████| 1680/1680 [00:14<00:00, 119.\u001b[0m\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/aidev/data/AI-Hub/ChildZoneCCTV/split/val/10_2020_11_21_15_4\u001b[0m\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/val/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00120.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/val/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00127.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/val/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00128.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/val/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00147.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/val/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00152.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.1GB ram): 100%|██████████| 210/210 [00:02<00:00, 104.25it\u001b[0m\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m3.13 anchors/target, 0.947 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mWARNING ⚠️ Extremely small objects found: 2045 of 32848 labels are <3 pixels in size\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 32848 points...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.7490: 100%|████\u001b[0m\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 4.33 anchors past thr\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=640, metric_all=0.286/0.749-mean/best, past_thr=0.473-mean: 6,5, 11,9, 6,20, 26,9, 12,29, 34,27, 113,60, 117,164, 256,234\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
            "Plotting labels to runs/train/exp8/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/exp8\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       0/99      3.24G     0.1245    0.06579    0.05046        401        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.532     0.0134     0.0109    0.00361\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       1/99      3.62G    0.09929    0.06775    0.02788        407        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.382      0.148     0.0986     0.0355\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       2/99      3.62G    0.09066    0.06356    0.01862        436        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.715      0.182      0.171     0.0672\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       3/99      3.62G    0.08297    0.05868    0.01423        712        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.685      0.287       0.29      0.111\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       4/99      3.62G    0.07609    0.05744    0.01208        426        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.714      0.319      0.371      0.164\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       5/99      3.62G    0.07161    0.05847    0.01082        639        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946        0.6      0.469      0.444      0.198\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       6/99      3.62G    0.06836    0.05483    0.00969        444        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946       0.66      0.472      0.499      0.227\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       7/99      3.62G    0.06594    0.05563   0.008907        511        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.565      0.521      0.538      0.248\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       8/99      3.62G     0.0641    0.05297   0.008206        446        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946       0.62      0.551      0.578      0.283\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       9/99      3.62G    0.06316    0.05249   0.007808        557        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.682      0.576      0.601      0.301\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      10/99      3.62G    0.06148    0.05197   0.007308        509        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.734      0.605      0.628      0.321\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      11/99      3.62G    0.06034    0.05118   0.007069        347        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.784      0.612       0.65       0.33\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      12/99      3.62G    0.05909    0.05053   0.006691        539        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.807      0.605      0.652      0.336\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      13/99      3.62G    0.05844    0.05032   0.006507        475        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.794      0.643      0.672      0.386\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      14/99      3.62G    0.05776     0.0512    0.00637        636        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.847      0.644      0.705      0.388\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      15/99      3.62G    0.05694    0.04911   0.006224        677        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946       0.78      0.645      0.679      0.384\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      16/99      3.62G    0.05545    0.04799   0.005992        546        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.819      0.678      0.727      0.412\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      17/99      3.62G    0.05587    0.04928   0.005979        488        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.864      0.646      0.721      0.394\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      18/99      3.62G    0.05573    0.04874   0.005829        698        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.732      0.744      0.754      0.409\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      19/99      3.62G    0.05449    0.04692   0.005737        428        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946       0.84      0.675      0.733      0.424\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      20/99      3.62G    0.05403     0.0477   0.005538        303        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946       0.88      0.657      0.755      0.429\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      21/99      3.62G    0.05363    0.04562   0.005469        430        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.814      0.676      0.752      0.413\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      22/99      3.62G    0.05342    0.04794   0.005456        481        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.842      0.646      0.769      0.451\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      23/99      3.62G    0.05285    0.04566   0.005389        327        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946       0.86      0.665       0.78      0.464\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      24/99      3.62G    0.05227     0.0458   0.005287        528        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.827      0.702      0.783      0.464\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      25/99      3.62G    0.05201    0.04574   0.005204        472        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.801      0.757      0.793      0.463\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      26/99      3.62G    0.05195     0.0447   0.005144        393        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946       0.75      0.796      0.808      0.478\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      27/99      3.62G    0.05145    0.04527   0.004959        630        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.781      0.758      0.818      0.481\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      28/99      3.62G    0.05107    0.04585   0.004969        405        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.784      0.794      0.827      0.491\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      29/99      3.62G    0.05088    0.04584   0.004927        504        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946       0.81      0.786      0.843      0.507\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      30/99      3.62G     0.0503     0.0438   0.004807        499        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946       0.78      0.775      0.836      0.511\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      31/99      3.62G    0.05017    0.04382   0.004801        505        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.802      0.781      0.829      0.509\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      32/99      3.62G    0.04966    0.04437   0.004702        550        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.852      0.759      0.822      0.495\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      33/99      3.62G    0.04964    0.04346   0.004753        526        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.824      0.798      0.855      0.524\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      34/99      3.62G    0.04952    0.04276   0.004681        535        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.823      0.804      0.836      0.531\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      35/99      3.62G    0.04875    0.04291   0.004638        481        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.849      0.808      0.854      0.516\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      36/99      3.62G    0.04855    0.04353   0.004576        637        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.841      0.784      0.847      0.536\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      37/99      3.62G    0.04867    0.04336   0.004484        499        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.844      0.804      0.839      0.537\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      38/99      3.62G    0.04787    0.04178   0.004443        357        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.842      0.842      0.858      0.544\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      39/99      3.62G    0.04821    0.04284   0.004516        453        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.862      0.795      0.853      0.544\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      40/99      3.62G    0.04798    0.04189   0.004471        468        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.872      0.792      0.858      0.546\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      41/99      3.62G    0.04758     0.0423   0.004407        572        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.824      0.791      0.847       0.54\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      42/99      3.62G    0.04754     0.0411   0.004372        568        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.871      0.814      0.857      0.534\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      43/99      3.62G    0.04737    0.04259   0.004301        617        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.875      0.806      0.861       0.54\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      44/99      3.62G    0.04697    0.04147   0.004363        391        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.873      0.809      0.864      0.556\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      45/99      3.62G    0.04716    0.04159   0.004293        480        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.888       0.82      0.863      0.557\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      46/99      3.62G    0.04634    0.04082   0.004219        513        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.865      0.826      0.857      0.556\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      47/99      3.62G    0.04607     0.0396    0.00419        668        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946       0.87      0.817      0.859      0.545\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      48/99      3.62G    0.04599    0.04034   0.004098        512        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.867      0.833      0.864      0.566\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      49/99      3.62G    0.04624    0.04142   0.004224        489        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.846       0.84      0.857      0.557\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      50/99      3.62G    0.04536    0.03945   0.004173        588        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.846      0.846      0.868      0.563\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      51/99      3.62G    0.04561    0.03991   0.004139        374        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.872      0.835      0.869      0.565\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      52/99      3.62G    0.04508    0.04088   0.004071        653        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.868      0.822      0.861      0.565\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      53/99      3.62G    0.04557    0.03904   0.004086        401        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.855      0.837       0.87      0.558\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      54/99      3.62G    0.04546    0.04048   0.004177        472        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.845      0.859       0.87      0.565\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      55/99      3.62G    0.04483    0.03956   0.004107        500        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.876      0.841      0.869      0.572\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      56/99      3.62G    0.04534    0.04051   0.004116        552        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.874      0.841      0.868      0.563\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      57/99      3.62G    0.04482    0.03961   0.004006        588        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.894      0.841      0.884      0.583\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      58/99      3.62G    0.04482    0.03991   0.004015        562        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.884      0.854      0.882      0.584\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      59/99      3.62G    0.04417     0.0387   0.003913        631        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.889      0.861        0.9      0.589\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      60/99      3.62G    0.04444     0.0387   0.003921        469        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.875      0.832      0.874      0.578\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      61/99      3.62G    0.04389    0.03883   0.003978        685        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.891      0.855       0.88      0.587\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      62/99      3.62G    0.04416    0.03915   0.003892        567        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.896      0.846      0.884      0.593\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      63/99      3.62G    0.04391    0.03953   0.003855        602        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.915      0.826      0.871      0.593\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      64/99      3.62G    0.04352    0.03823   0.003847        539        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.896      0.865      0.887      0.594\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      65/99      3.62G    0.04289    0.03803   0.003787        559        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.897      0.848      0.882      0.601\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      66/99      3.62G    0.04347     0.0386   0.003821        549        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.893      0.853      0.883      0.599\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      67/99      3.62G    0.04338    0.03874   0.003887        588        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.905      0.839      0.877      0.595\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      68/99      3.62G    0.04288    0.03796   0.003785        597        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946        0.9      0.826      0.876      0.597\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      69/99      3.62G    0.04227    0.03689   0.003765        462        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.917      0.859      0.889      0.602\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      70/99      3.62G    0.04248    0.03689    0.00378        350        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.904      0.848      0.888      0.596\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      71/99      3.62G    0.04245    0.03705   0.003758        560        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.906      0.843      0.886      0.599\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      72/99      3.62G    0.04217    0.03682   0.003727        553        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.913      0.829      0.874      0.597\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      73/99      3.62G     0.0424    0.03739   0.003758        517        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.903      0.838      0.882      0.591\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      74/99      3.62G    0.04171    0.03594    0.00369        494        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.903      0.852      0.884      0.607\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      75/99      3.62G    0.04212    0.03685   0.003712        625        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.903      0.848      0.876      0.605\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      76/99      3.62G    0.04143    0.03599    0.00371        468        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.906      0.842      0.876      0.615\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      77/99      3.62G    0.04141    0.03677   0.003629        359        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.901      0.844      0.887      0.604\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      78/99      3.62G    0.04116    0.03564   0.003629        417        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.913      0.834       0.88      0.599\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      79/99      3.62G    0.04072    0.03547   0.003601        352        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.902      0.846      0.876      0.601\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      80/99      3.62G    0.04119    0.03574   0.003605        610        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.929      0.832      0.891      0.617\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      81/99      3.62G    0.04066    0.03579   0.003595        438        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.923       0.84      0.887      0.612\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      82/99      3.62G    0.04063    0.03502   0.003528        533        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.909      0.851      0.886      0.622\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      83/99      3.62G    0.04077    0.03538   0.003508        498        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946       0.89      0.853      0.882      0.609\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      84/99      3.62G    0.04045    0.03536   0.003495        464        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.911      0.848      0.888      0.622\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      85/99      3.62G    0.04082    0.03549   0.003509        636        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.939      0.854      0.887      0.625\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      86/99      3.62G    0.04028    0.03471   0.003544        584        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.916      0.851      0.887      0.615\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      87/99      3.62G    0.03986    0.03414    0.00345        518        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.932      0.837      0.884      0.608\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      88/99      3.62G    0.04036    0.03436   0.003544        387        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.934      0.855      0.893      0.625\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      89/99      3.62G    0.04012    0.03464   0.003479        364        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.918      0.851       0.89       0.62\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      90/99      3.62G    0.03943    0.03387   0.003346        435        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.946      0.837      0.889      0.616\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      91/99      3.62G    0.03938    0.03296   0.003345        497        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946        0.9      0.853      0.886      0.613\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      92/99      3.62G    0.04024    0.03532   0.003462        576        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.926      0.844      0.886      0.623\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      93/99      3.62G    0.03936     0.0333   0.003376        606        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.926      0.842      0.884      0.619\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      94/99      3.62G    0.03987    0.03487   0.003431        628        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.913      0.845      0.888      0.619\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      95/99      3.62G    0.03924    0.03288   0.003432        477        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.925      0.844      0.889       0.62\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      96/99      3.62G    0.03995    0.03488   0.003433        679        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.926      0.846       0.89      0.625\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      97/99      3.62G    0.03917    0.03281   0.003392        550        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.912      0.857      0.892      0.629\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      98/99      3.62G    0.03962    0.03357   0.003378        434        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.924      0.853      0.892      0.627\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      99/99      3.62G    0.03963    0.03435   0.003397        620        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.922      0.857      0.892       0.63\n",
            "\n",
            "100 epochs completed in 0.224 hours.\n",
            "Optimizer stripped from runs/train/exp8/weights/last.pt, 14.5MB\n",
            "Optimizer stripped from runs/train/exp8/weights/best.pt, 14.5MB\n",
            "\n",
            "Validating runs/train/exp8/weights/best.pt...\n",
            "Fusing layers... \n",
            "train_cfg summary: 166 layers, 7078183 parameters, 0 gradients\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.921      0.857      0.892       0.63\n",
            "                person        210        671        0.9      0.802      0.854      0.539\n",
            "               vehicle        210       1894      0.931      0.887      0.948      0.758\n",
            "                 cycle        210         22      0.911       0.93       0.96      0.549\n",
            "                  kick        210        159      0.884      0.766      0.801      0.527\n",
            "                  face        210         44      0.863      0.841      0.875      0.428\n",
            "         license_plate        210        397      0.894      0.698      0.715      0.542\n",
            "         traffic_light        210        668       0.99          1      0.995      0.855\n",
            "             motorbike        210         91      0.999      0.934      0.993      0.839\n",
            "Results saved to \u001b[1mruns/train/exp8\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▂▄▅▆▆▆▇▇▇▇▇████████████████████████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▂▃▄▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇████████████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▄▂▂▅▆▅▇▇▇▆▅▅▆▇▆▆▇▇▇▇▇▇▇▇▇▇██▇█▇████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▂▅▅▆▆▆▆▆▆▇▇▇▇██▇███████████████████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▅▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ██▆▆▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss █▅▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss █▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss █▆▅▅▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 █▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▃████▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ▃████▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 99\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.89246\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 0.62962\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.92153\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.85717\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.8924\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.6295\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.92141\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.85721\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.03963\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.0034\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.03435\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.03576\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.0033\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.03354\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.0003\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.0003\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.0003\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mlunar-peony-371\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/changsin/YOLOv5/runs/38wf7qjn\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 337 media file(s), 1 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230204_154221-38wf7qjn/logs\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "train_folder = DATA_ROOT + \"train\"\n",
        "val_folder = DATA_ROOT + \"val\"\n",
        "\n",
        "train_yolo(train_folder,\n",
        "           val_folder,\n",
        "           batch_size=16,\n",
        "           epochs=100,\n",
        "           weights_path=\"yolov5s.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Set train to /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train\n",
            "Set val to /home/aidev/data/AI-Hub/ChildZoneCCTV/split/val\n",
            "Set nc to 10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mchangsin\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=/home/aidev/data/AI-Hub/ChildZoneCCTV/split/train_cfg.yaml, data=/home/aidev/data/AI-Hub/ChildZoneCCTV/split/train_data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=100, batch_size=32, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
            "YOLOv5 🚀 v7.0-72-g064365d8 Python-3.10.6 torch-1.13.1+cu117 CUDA:0 (NVIDIA GeForce RTX 3080 Ti, 12037MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "2023-02-04 15:58:39.523695: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-02-04 15:58:39.969530: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/aidev/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
            "2023-02-04 15:58:39.969576: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/aidev/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
            "2023-02-04 15:58:39.969582: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-02-04 15:58:41.133984: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-02-04 15:58:41.201077: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/aidev/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
            "2023-02-04 15:58:41.201097: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
            "2023-02-04 15:58:41.513257: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/aidev/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
            "2023-02-04 15:58:41.513299: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/aidev/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
            "2023-02-04 15:58:41.513305: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.13.9 is available!  To upgrade, please run:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.17\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/aidev/workspace/yolov5/wandb/run-20230204_155840-3i7oq9ef\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mchromatic-fish-373\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/changsin/YOLOv5\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/changsin/YOLOv5/runs/3i7oq9ef\u001b[0m\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
            "  9                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     40455  models.yolo.Detect                      [10, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "train_cfg summary: 225 layers, 7087815 parameters, 7087815 gradients\n",
            "\n",
            "Transferred 308/361 items from yolov5s.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 59 weight(decay=0.0), 62 weight(decay=0.0005), 62 bias\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_21_\u001b[0m\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00091.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00095.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00096.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00097.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00098.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00099.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00100.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00101.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00102.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00103.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00104.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00105.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00106.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00107.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00108.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00110.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00111.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00112.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00113.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00114.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00115.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00117.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00118.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00119.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00121.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00122.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00123.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00124.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00125.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00126.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00130.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00133.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00136.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00137.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00138.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00139.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00140.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00145.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00146.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00148.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00149.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00150.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00151.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00159.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00160.jpg: 3 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00161.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00162.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00163.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00164.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00186.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00240.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00241.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/train/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00242.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (1.1GB ram): 100%|██████████| 1680/1680 [00:14<00:00, 119.\u001b[0m\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/aidev/data/AI-Hub/ChildZoneCCTV/split/val/10_2020_11_21_15_4\u001b[0m\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/val/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00120.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/val/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00127.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/val/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00128.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/val/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00147.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/split/val/10_2020_11_25_17_40_with_dog_night_A_01/2020_11_25_17_40_with_dog_night_A_01_00152.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.1GB ram): 100%|██████████| 210/210 [00:02<00:00, 102.51it\u001b[0m\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m3.13 anchors/target, 0.947 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mWARNING ⚠️ Extremely small objects found: 2045 of 32848 labels are <3 pixels in size\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 32848 points...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.7490: 100%|████\u001b[0m\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 4.33 anchors past thr\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=640, metric_all=0.286/0.749-mean/best, past_thr=0.473-mean: 6,5, 11,9, 6,20, 26,9, 12,29, 34,27, 113,60, 117,164, 256,234\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
            "Plotting labels to runs/train/exp10/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/exp10\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       0/99      6.54G      0.125    0.06501    0.05122        430        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946    0.00151     0.0312    0.00696    0.00198\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       1/99       7.3G    0.09986    0.06787    0.02922        407        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.592     0.0562     0.0374     0.0137\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       2/99       7.3G    0.09253    0.06419    0.02071        611        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.218      0.258      0.124     0.0375\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       3/99       7.3G    0.08473    0.05905    0.01509        712        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.677      0.254      0.242     0.0929\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       4/99       7.3G    0.07646    0.05777    0.01237        616        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.673      0.294      0.314      0.124\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       5/99       7.3G    0.07192    0.05881    0.01091        639        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.767      0.335      0.453      0.212\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       6/99       7.3G    0.06917    0.05558   0.009815        480        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.591      0.466      0.449       0.22\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       7/99       7.3G    0.06621    0.05548   0.008932        511        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.541      0.554      0.546       0.27\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       8/99       7.3G    0.06456    0.05257   0.008316        539        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946       0.68      0.566      0.612      0.312\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       9/99       7.3G    0.06285    0.05239   0.007783        557        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.705      0.554      0.591      0.283\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      10/99       7.3G    0.06187    0.05221   0.007335        481        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.756       0.59      0.649      0.339\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      11/99       7.3G     0.0601    0.05166   0.007029        347        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.806      0.568       0.63      0.329\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      12/99       7.3G    0.05968    0.05065   0.006861        566        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.807      0.583      0.637      0.317\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      13/99       7.3G    0.05805    0.04986   0.006476        475        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.806      0.635      0.661      0.379\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      14/99       7.3G    0.05788    0.05045   0.006336        443        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.816      0.626      0.692       0.38\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      15/99       7.3G    0.05705    0.04952   0.006328        677        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.848      0.602      0.683      0.369\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      16/99       7.3G    0.05617    0.04797   0.006031        626        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.848      0.654      0.705      0.384\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      17/99       7.3G    0.05586    0.04871   0.006041        488        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.877      0.625      0.721      0.407\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      18/99       7.3G     0.0557    0.04874   0.005805        475        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.727      0.666      0.711      0.399\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      19/99       7.3G    0.05444     0.0468   0.005704        428        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.758      0.706      0.758      0.423\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      20/99       7.3G    0.05468    0.04852    0.00559        465        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.835      0.706      0.789      0.443\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      21/99       7.3G    0.05315    0.04558    0.00542        430        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.815      0.711      0.779      0.435\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      22/99       7.3G     0.0537    0.04757   0.005472        357        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.714      0.723       0.75      0.445\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      23/99       7.3G    0.05281    0.04539   0.005336        327        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.854      0.717       0.79      0.434\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      24/99       7.3G     0.0529    0.04606   0.005273        520        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.729      0.756      0.791      0.464\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      25/99       7.3G    0.05241    0.04573   0.005223        472        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.792      0.771      0.826      0.494\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      26/99       7.3G    0.05155    0.04478   0.005075        428        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.787      0.766       0.82      0.484\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      27/99       7.3G     0.0517    0.04579   0.005001        630        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.793      0.764       0.81       0.49\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      28/99       7.3G    0.05144    0.04622    0.00501        539        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.788      0.754       0.79       0.48\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      29/99       7.3G    0.05132    0.04554   0.004968        504        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.793       0.78      0.825      0.505\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      30/99       7.3G    0.05055    0.04401    0.00484        431        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.809       0.79      0.815      0.484\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      31/99       7.3G    0.05045    0.04356   0.004817        505        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.838      0.799      0.849      0.508\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      32/99       7.3G    0.05003    0.04405   0.004772        440        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.827      0.774      0.824      0.505\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      33/99       7.3G    0.05013    0.04316   0.004845        526        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.829      0.781      0.836      0.511\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      34/99       7.3G    0.04951    0.04235    0.00471        492        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.804      0.783      0.843      0.522\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      35/99       7.3G    0.04887    0.04358   0.004603        481        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.806      0.795      0.838      0.522\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      36/99       7.3G     0.0489    0.04345   0.004605        421        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.861      0.804       0.86      0.523\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      37/99       7.3G    0.04913    0.04373    0.00452        499        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.839       0.83      0.859      0.531\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      38/99       7.3G    0.04837    0.04246   0.004542        536        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.869      0.794       0.85       0.53\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      39/99       7.3G    0.04814    0.04195    0.00456        453        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.871      0.803      0.861      0.547\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      40/99       7.3G    0.04833    0.04187    0.00449        592        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.869       0.83      0.876      0.553\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      41/99       7.3G    0.04773    0.04231   0.004411        572        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.857      0.842      0.871      0.564\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      42/99       7.3G    0.04783    0.04148   0.004453        594        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.859      0.816      0.855      0.531\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      43/99       7.3G    0.04766    0.04265   0.004367        617        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.857      0.801      0.843      0.539\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      44/99       7.3G    0.04693    0.04142   0.004368        605        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.879      0.823      0.875      0.561\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      45/99       7.3G    0.04703    0.04109   0.004305        480        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.895      0.811      0.859      0.546\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      46/99       7.3G    0.04594    0.04018   0.004217        342        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.861      0.817      0.853      0.546\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      47/99       7.3G    0.04677    0.04025   0.004272        668        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.866      0.821      0.865      0.549\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      48/99       7.3G    0.04631    0.04058   0.004223        262        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.887       0.86      0.896       0.58\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      49/99       7.3G    0.04607    0.04152   0.004264        489        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946       0.86      0.824      0.869      0.556\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      50/99       7.3G    0.04534    0.03922   0.004168        619        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.897      0.803      0.872      0.559\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      51/99       7.3G    0.04597    0.04032   0.004139        374        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.891      0.825      0.871      0.562\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      52/99       7.3G    0.04535    0.04066   0.004102        489        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.872      0.848      0.865      0.567\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      53/99       7.3G    0.04551    0.03896   0.004138        401        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946       0.87      0.837      0.866      0.568\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      54/99       7.3G    0.04553    0.04048   0.004173        521        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.898      0.853      0.894      0.586\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      55/99       7.3G    0.04462    0.03943   0.004116        500        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.901       0.84      0.886      0.581\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      56/99       7.3G    0.04565    0.04045   0.004145        731        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.879      0.843      0.867      0.556\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      57/99       7.3G    0.04516    0.03961   0.004023        588        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.908      0.831      0.863      0.559\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      58/99       7.3G    0.04485     0.0396   0.004027        714        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.895      0.836      0.875      0.567\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      59/99       7.3G    0.04446    0.03869   0.003973        631        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.897      0.831      0.869      0.566\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      60/99       7.3G    0.04443    0.03847   0.003976        453        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.888      0.847      0.874       0.57\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      61/99       7.3G    0.04419    0.03891   0.004001        685        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.904      0.821      0.863      0.569\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      62/99       7.3G    0.04437    0.03917   0.003929        501        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.913      0.831      0.874      0.576\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      63/99       7.3G    0.04418    0.03988   0.003876        602        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.907      0.834      0.878      0.589\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      64/99       7.3G     0.0441    0.03828   0.003869        394        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.919       0.85      0.892      0.602\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      65/99       7.3G    0.04316    0.03796   0.003825        559        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.911      0.836      0.872       0.59\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      66/99       7.3G    0.04345    0.03809    0.00386        599        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.909      0.834      0.871      0.588\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      67/99       7.3G    0.04348    0.03858   0.003913        588        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.912      0.843      0.877      0.596\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      68/99       7.3G    0.04301    0.03757   0.003773        427        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.897      0.844      0.875      0.595\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      69/99       7.3G    0.04245    0.03694   0.003795        462        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.901      0.847      0.881      0.602\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      70/99       7.3G    0.04245    0.03689   0.003792        499        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.906      0.845      0.886       0.61\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      71/99       7.3G    0.04265    0.03712   0.003751        560        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946       0.92      0.829       0.88      0.607\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      72/99       7.3G    0.04227    0.03641   0.003749        543        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946       0.92      0.842      0.878      0.608\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      73/99       7.3G    0.04243    0.03704   0.003742        517        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.902      0.852      0.871      0.604\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      74/99       7.3G     0.0421    0.03603   0.003729        298        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.932      0.833      0.877      0.599\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      75/99       7.3G    0.04227    0.03712   0.003701        625        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.895      0.854      0.883      0.607\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      76/99       7.3G    0.04167    0.03564   0.003715        513        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.917      0.844      0.878      0.612\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      77/99       7.3G    0.04168    0.03693   0.003603        359        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.922      0.856      0.897      0.617\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      78/99       7.3G    0.04133    0.03538   0.003612        485        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.905      0.846      0.884      0.609\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      79/99       7.3G    0.04101     0.0358   0.003582        352        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.901      0.843      0.881       0.61\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      80/99       7.3G    0.04124    0.03561   0.003583        395        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.918      0.836      0.876      0.609\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      81/99       7.3G    0.04087    0.03545   0.003598        438        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.923       0.84      0.876       0.61\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      82/99       7.3G     0.0406    0.03478   0.003549        391        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.911      0.848      0.882       0.62\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      83/99       7.3G    0.04085    0.03545   0.003491        498        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.929      0.842      0.891      0.619\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      84/99       7.3G    0.04092    0.03529   0.003514        425        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946       0.93      0.848      0.885       0.62\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      85/99       7.3G     0.0407    0.03503   0.003489        636        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946       0.92      0.856      0.891      0.628\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      86/99       7.3G    0.04064    0.03467   0.003582        422        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.919       0.84      0.879       0.62\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      87/99       7.3G    0.04027    0.03437   0.003443        518        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.914      0.846      0.883      0.613\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      88/99       7.3G    0.04021    0.03413   0.003533        444        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.908      0.852      0.886      0.629\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      89/99       7.3G     0.0404     0.0347   0.003522        364        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.907      0.843      0.881      0.622\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      90/99       7.3G    0.03973    0.03384   0.003359        552        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.911      0.845      0.883      0.622\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      91/99       7.3G    0.03964    0.03344    0.00339        497        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.928      0.835      0.874      0.615\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      92/99       7.3G     0.0403    0.03481    0.00349        469        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.903      0.848      0.882      0.632\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      93/99       7.3G    0.03973    0.03343   0.003392        606        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.917      0.835      0.884      0.629\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      94/99       7.3G    0.04022    0.03494   0.003468        415        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.922      0.844      0.881       0.63\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      95/99       7.3G    0.03951    0.03317   0.003426        477        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.919      0.838      0.881      0.635\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      96/99       7.3G    0.03991    0.03452   0.003436        615        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946       0.91       0.84      0.877      0.624\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      97/99       7.3G     0.0394     0.0329   0.003395        550        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.915      0.842      0.883      0.627\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      98/99       7.3G    0.03944    0.03331   0.003385        500        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.916      0.836      0.878       0.63\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      99/99       7.3G    0.03975    0.03402   0.003432        620        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.911      0.839      0.881      0.631\n",
            "\n",
            "100 epochs completed in 0.202 hours.\n",
            "Optimizer stripped from runs/train/exp10/weights/last.pt, 14.5MB\n",
            "Optimizer stripped from runs/train/exp10/weights/best.pt, 14.5MB\n",
            "\n",
            "Validating runs/train/exp10/weights/best.pt...\n",
            "Fusing layers... \n",
            "train_cfg summary: 166 layers, 7078183 parameters, 0 gradients\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        210       3946      0.918       0.84      0.881      0.635\n",
            "                person        210        671      0.912        0.8      0.858      0.544\n",
            "               vehicle        210       1894       0.91      0.868       0.94       0.74\n",
            "                 cycle        210         22      0.976      0.864      0.961      0.603\n",
            "                  kick        210        159      0.976      0.756      0.827      0.518\n",
            "                  face        210         44      0.738      0.795      0.767      0.408\n",
            "         license_plate        210        397      0.872      0.695      0.715      0.582\n",
            "         traffic_light        210        668      0.982      0.999      0.995      0.858\n",
            "             motorbike        210         91      0.977      0.943      0.986      0.829\n",
            "Results saved to \u001b[1mruns/train/exp10\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▂▅▅▆▆▆▇▇▇▇▇▇███████████████████████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▃▄▅▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇█████████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▃▇▅▇▇▇█▇▇▇▇▇▇▇█▇▇▇█████████████████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▃▄▅▆▆▆▆▇▇▇▇▇▇▇▇████████████████████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▅▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▄▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ██▇▆▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss █▅▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss █▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss █▆▄▄▄▃▃▃▃▃▂▂▃▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 █▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▃████▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ▃████▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 95\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.88085\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 0.63507\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.91854\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.83772\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.8811\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.63519\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.91776\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.83996\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.03975\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.00343\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.03402\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.03728\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.00322\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.03629\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.0003\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.0003\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.0003\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mchromatic-fish-373\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/changsin/YOLOv5/runs/3i7oq9ef\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 337 media file(s), 1 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230204_155840-3i7oq9ef/logs\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "train_folder = DATA_ROOT + \"train\"\n",
        "val_folder = DATA_ROOT + \"val\"\n",
        "\n",
        "train_yolo(train_folder,\n",
        "           val_folder,\n",
        "           batch_size=32,\n",
        "           epochs=100,\n",
        "           weights_path=\"yolov5s.pt\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Original labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train.py --img 640 --batch 32 --epochs 100 --data /home/aidev/workspace/ClassifyImages/data/configs/yolov5_train_childzone_ai-hub.yaml --cfg /home/aidev/workspace/ClassifyImages/data/configs/train_cfg_childzone.yaml --weights yolov5s.pt --cache\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mchangsin\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=/home/aidev/workspace/ClassifyImages/data/configs/train_cfg_childzone.yaml, data=/home/aidev/workspace/ClassifyImages/data/configs/yolov5_train_childzone_ai-hub.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=100, batch_size=32, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0m⚠️ YOLOv5 is out of date by 8 commits. Use `git pull` or `git clone https://github.com/ultralytics/yolov5` to update.\n",
            "YOLOv5 🚀 v7.0-72-g064365d8 Python-3.10.6 torch-1.13.1+cu117 CUDA:0 (NVIDIA GeForce RTX 3080 Ti, 12037MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "2023-02-08 13:57:09.368324: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-02-08 13:57:09.829708: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/aidev/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
            "2023-02-08 13:57:09.829756: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/aidev/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
            "2023-02-08 13:57:09.829762: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-02-08 13:57:11.096017: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-02-08 13:57:11.171852: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/aidev/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
            "2023-02-08 13:57:11.171874: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
            "2023-02-08 13:57:11.482990: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/aidev/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
            "2023-02-08 13:57:11.483035: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/aidev/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
            "2023-02-08 13:57:11.483041: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.13.10 is available!  To upgrade, please run:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.17\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/aidev/workspace/yolov5/wandb/run-20230208_135710-20ryh3ag\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mnoble-bee-380\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/changsin/YOLOv5\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/changsin/YOLOv5/runs/20ryh3ag\u001b[0m\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
            "  9                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     40455  models.yolo.Detect                      [10, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "train_cfg_childzone summary: 225 layers, 7087815 parameters, 7087815 gradients\n",
            "\n",
            "Transferred 308/361 items from yolov5s.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 59 weight(decay=0.0), 62 weight(decay=0.0005), 62 bias\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train.cache... \u001b[0m\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00001.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00003.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00004.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00005.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00007.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00008.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00010.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00012.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00013.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00015.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00016.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00017.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00019.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00021.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00023.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00025.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00026.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00027.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00030.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00031.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00032.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00033.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00036.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00039.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00040.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00041.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00042.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00043.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00044.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00045.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00046.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00047.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00048.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00049.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00050.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00051.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00052.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00053.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00054.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00055.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00056.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00057.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00058.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00059.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00060.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00062.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00063.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00065.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00066.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00068.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00069.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00070.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00072.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00073.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00074.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00075.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00076.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00077.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00080.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00081.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00082.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00083.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00084.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00086.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00087.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00088.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00089.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00090.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00091.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00093.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00094.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00095.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00096.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00097.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00100.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00101.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00102.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00103.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00104.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00107.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00109.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00110.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00112.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00113.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00114.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00115.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00116.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00118.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00119.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00120.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00121.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00122.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00123.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00124.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00125.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00126.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00127.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00129.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00130.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00132.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00133.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00134.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00135.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00136.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00137.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00138.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00139.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00140.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00141.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00142.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00143.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00145.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00146.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00147.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00148.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00150.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00151.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00152.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00153.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00154.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00156.jpg: 3 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00157.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00158.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00159.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00160.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00161.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00162.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00163.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00164.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00165.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00168.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00169.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00170.jpg: 3 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00171.jpg: 3 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00173.jpg: 4 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00174.jpg: 4 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00175.jpg: 4 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00176.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00177.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00178.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00179.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00180.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00181.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00183.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00184.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00185.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00186.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00187.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00188.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00189.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00190.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00192.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00193.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00195.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00196.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00197.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00198.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00199.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00201.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00202.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00203.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00204.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00205.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00206.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00208.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00209.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00210.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00211.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00212.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00213.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00214.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00216.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00217.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00218.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00219.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00220.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00221.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00222.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00223.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00225.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00226.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00229.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00230.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00231.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00232.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00233.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00234.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00235.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00236.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00238.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00239.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00240.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00241.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00244.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00245.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00246.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00247.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00248.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00249.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00250.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00251.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00252.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00253.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00254.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00255.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00256.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00257.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00258.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00259.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00262.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00264.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00265.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00266.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00269.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00270.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00271.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00272.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00273.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00274.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00275.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00276.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00277.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00278.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00279.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00280.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00281.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00282.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00283.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00284.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00285.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00286.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00287.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00288.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00289.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00290.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00291.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00292.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00293.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00294.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00295.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00297.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00298.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00299.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/train/2020_12_02_16_30_ride_kick_sun_A_01_00300.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (11.1GB ram): 100%|██████████| 17280/17280 [02:25<00:00, 1\u001b[0m\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/val.cache... 2160\u001b[0m\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/val/2020_12_02_16_30_ride_kick_sun_A_01_00009.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/val/2020_12_02_16_30_ride_kick_sun_A_01_00014.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/val/2020_12_02_16_30_ride_kick_sun_A_01_00034.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/val/2020_12_02_16_30_ride_kick_sun_A_01_00038.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/val/2020_12_02_16_30_ride_kick_sun_A_01_00061.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/val/2020_12_02_16_30_ride_kick_sun_A_01_00071.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/val/2020_12_02_16_30_ride_kick_sun_A_01_00079.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/val/2020_12_02_16_30_ride_kick_sun_A_01_00085.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/val/2020_12_02_16_30_ride_kick_sun_A_01_00092.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/val/2020_12_02_16_30_ride_kick_sun_A_01_00105.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/val/2020_12_02_16_30_ride_kick_sun_A_01_00106.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/val/2020_12_02_16_30_ride_kick_sun_A_01_00111.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/val/2020_12_02_16_30_ride_kick_sun_A_01_00117.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/val/2020_12_02_16_30_ride_kick_sun_A_01_00128.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/val/2020_12_02_16_30_ride_kick_sun_A_01_00131.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/val/2020_12_02_16_30_ride_kick_sun_A_01_00144.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/val/2020_12_02_16_30_ride_kick_sun_A_01_00155.jpg: 3 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/val/2020_12_02_16_30_ride_kick_sun_A_01_00191.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/val/2020_12_02_16_30_ride_kick_sun_A_01_00200.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/val/2020_12_02_16_30_ride_kick_sun_A_01_00228.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/val/2020_12_02_16_30_ride_kick_sun_A_01_00242.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/val/2020_12_02_16_30_ride_kick_sun_A_01_00243.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/val/2020_12_02_16_30_ride_kick_sun_A_01_00263.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/val/2020_12_02_16_30_ride_kick_sun_A_01_00267.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (1.4GB ram): 100%|██████████| 2160/2160 [00:21<00:00, 100.75\u001b[0m\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m3.54 anchors/target, 0.935 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mWARNING ⚠️ Extremely small objects found: 14992 of 246517 labels are <3 pixels in size\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 245977 points...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.7089: 100%|████\u001b[0m\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.25: 0.9860 best possible recall, 4.49 anchors past thr\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=640, metric_all=0.297/0.710-mean/best, past_thr=0.467-mean: 9,7, 7,18, 24,10, 12,28, 41,23, 27,55, 68,46, 128,71, 172,164\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
            "Plotting labels to runs/train/exp6/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/exp6\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       0/99      6.54G    0.09748    0.07066    0.03375        724        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       2160      30867      0.595      0.209      0.187     0.0734\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       1/99       7.3G    0.07313    0.06056    0.01419        564        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       2160      30867        0.7      0.346      0.399      0.187\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       2/99       7.3G      0.067    0.05664    0.01016        742        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       2160      30867      0.753      0.451      0.508      0.265\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       3/99       7.3G    0.06083    0.05358    0.00786        799        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       2160      30867       0.78      0.535      0.592      0.319\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       4/99       7.3G    0.05637     0.0508    0.00662        682        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       2160      30867      0.774      0.572      0.645      0.371\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       5/99       7.3G    0.05348    0.04896   0.005948        622        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       2160      30867      0.822      0.614       0.67      0.385\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       6/99       7.3G    0.05161    0.04762   0.005577        644        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       2160      30867      0.798      0.641      0.689      0.408\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       7/99       7.3G    0.05004    0.04599   0.005253        895        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       2160      30867      0.837      0.639        0.7      0.425\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       8/99       7.3G    0.04904    0.04497   0.005072        726        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       2160      30867      0.812      0.658      0.708      0.433\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       9/99       7.3G    0.04829    0.04445   0.004955        788        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       2160      30867      0.826       0.67      0.722      0.435\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      10/99       7.3G     0.0477    0.04408    0.00482        828        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       2160      30867      0.856      0.643      0.717      0.442\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      11/99       7.3G    0.04706    0.04378   0.004712        842        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       2160      30867      0.827      0.677      0.726      0.454\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      12/99       7.3G    0.04683    0.04327    0.00467        772        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       2160      30867      0.841      0.678      0.725      0.461\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      13/99       7.3G    0.04626    0.04283   0.004569        747        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       2160      30867      0.842      0.687      0.747      0.474\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      14/99       7.3G    0.04576    0.04204   0.004458        673        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       2160      30867      0.826      0.701      0.749      0.477\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      15/99       7.3G    0.04557    0.04201   0.004436        806        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       2160      30867      0.836      0.678      0.746      0.481\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      16/99       7.3G    0.04516     0.0418   0.004393        790        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       2160      30867      0.855      0.686      0.753      0.486\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      17/99       7.3G     0.0449    0.04129   0.004353        724        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       2160      30867      0.848      0.697      0.757      0.486\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      18/99       7.3G    0.04472    0.04121   0.004336        732        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       2160      30867      0.866      0.706      0.767      0.496\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      19/99       7.3G     0.0445    0.04077   0.004301        679        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       2160      30867      0.835      0.717       0.77      0.501\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      20/99       7.3G    0.04419    0.04058   0.004239        725        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       2160      30867      0.881      0.688      0.763      0.502\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      21/99       7.3G    0.04422    0.04095   0.004207       1011        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       2160      30867      0.829      0.723      0.766      0.509\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      22/99       7.3G    0.04377    0.03995   0.004217        772        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       2160      30867       0.83      0.729      0.771      0.507\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      23/99       7.3G    0.04348    0.03981   0.004158        834        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       2160      30867      0.839      0.737      0.778      0.511\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      24/99       7.3G    0.04341    0.04018   0.004102        707        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       2160      30867      0.829      0.727      0.771      0.513\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      25/99       7.3G    0.04324    0.03955   0.004122        725        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       2160      30867      0.845      0.725      0.777      0.514\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      26/99       7.3G    0.04305    0.03962   0.004103        812        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       2160      30867      0.855       0.73      0.777      0.523\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      27/99       7.3G    0.04287    0.03918   0.004075        672        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       2160      30867      0.854      0.729      0.786      0.525\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      28/99       7.3G    0.04274    0.03922   0.004046        629        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       2160      30867      0.867      0.725      0.782      0.525\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      29/99       7.3G    0.04271    0.03905   0.003991        721        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       2160      30867      0.868      0.726      0.788       0.53\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      30/99       7.3G    0.04235    0.03896   0.003999        669        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       2160      30867      0.836      0.741      0.788      0.534\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      31/99       7.3G    0.04227    0.03851   0.003985        679        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       2160      30867      0.867      0.738      0.794      0.535\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      32/99       7.3G    0.04217    0.03877   0.003963        787        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       2160      30867      0.869      0.737      0.793      0.536\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      33/99       7.3G    0.04212    0.03844   0.003946        792        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       2160      30867      0.859      0.749      0.794      0.539\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      34/99       7.3G    0.04194    0.03843   0.003939        780        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       2160      30867      0.853      0.748      0.797      0.539\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      35/99       7.3G    0.04196    0.03863   0.003908        724        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       2160      30867      0.873      0.731      0.796      0.541\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      36/99       7.3G    0.04177     0.0381   0.003937        747        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       2160      30867      0.864      0.741      0.798      0.541\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      37/99       7.3G    0.04168    0.03808   0.003876        638        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       2160      30867       0.86      0.749      0.798      0.546\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      38/99       7.3G    0.04156    0.03759   0.003832        860        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       2160      30867      0.851      0.754        0.8      0.545\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      39/99       7.3G    0.04133    0.03771    0.00384        861        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       2160      30867      0.862      0.752      0.801      0.549\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      40/99       7.3G    0.04123    0.03746   0.003855        685        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       2160      30867      0.869      0.758      0.803      0.548\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      41/99       7.3G    0.04117    0.03758     0.0038        775        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       2160      30867       0.85      0.759      0.801      0.548\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      42/99       7.3G    0.04114    0.03734   0.003815        724        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       2160      30867      0.854      0.754      0.799      0.549\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      43/99       7.3G    0.04087    0.03743   0.003803        575        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       2160      30867      0.854      0.754      0.799      0.551\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      44/99       7.3G    0.04076    0.03703   0.003795        774        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       2160      30867      0.851       0.76      0.804      0.552\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      45/99       7.3G    0.04074    0.03714   0.003781        537        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       2160      30867      0.858      0.756      0.803      0.553\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      46/99       7.3G    0.04075    0.03682   0.003756        838        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       2160      30867      0.859      0.758      0.804      0.556\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      47/99       7.3G    0.04048    0.03657   0.003768        775        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       2160      30867      0.866      0.756      0.806      0.557\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      48/99       7.3G    0.04055    0.03668    0.00372        731        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       2160      30867       0.87      0.757      0.809       0.56\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      49/99       7.3G    0.04015    0.03629   0.003733        744        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       2160      30867      0.872      0.754       0.81       0.56\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      50/99       7.3G    0.04026    0.03634   0.003741        769        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       2160      30867      0.873      0.753      0.811      0.561\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      51/99       7.3G    0.04012    0.03637   0.003718        741        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       2160      30867      0.877      0.753       0.81      0.562\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      52/99       7.3G    0.04002    0.03614    0.00371        761        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       2160      30867      0.874      0.758      0.811      0.564\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      53/99       7.3G    0.04017    0.03624   0.003682        825        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       2160      30867      0.882      0.753      0.811      0.564\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      54/99       7.3G    0.03997     0.0362   0.003664        734        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       2160      30867      0.871      0.758      0.813      0.565\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      55/99       7.3G    0.03977    0.03604   0.003675        859        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       2160      30867      0.871      0.762      0.814      0.566\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      56/99       7.3G    0.03966     0.0357   0.003681        789        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       2160      30867       0.87      0.763      0.814      0.566\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      57/99       7.3G    0.03952    0.03563   0.003651        734        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       2160      30867      0.874       0.76      0.815      0.567\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      58/99       7.3G    0.03957    0.03552   0.003635        703        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       2160      30867      0.878      0.762      0.817      0.569\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      59/99       7.3G    0.03945    0.03554   0.003643        625        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       2160      30867      0.879      0.761      0.817      0.569\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      60/99       7.3G    0.03947    0.03574    0.00364        670        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       2160      30867      0.876       0.76      0.818       0.57\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      61/99       7.3G    0.03933    0.03539   0.003611        756        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       2160      30867      0.867      0.769      0.819      0.572\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      62/99       7.3G    0.03912    0.03535   0.003592        925        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       2160      30867       0.87      0.767      0.819      0.573\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      63/99       7.3G    0.03905    0.03506   0.003585        704        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       2160      30867      0.876      0.762      0.819      0.573\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      64/99       7.3G    0.03885    0.03497   0.003553        907        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       2160      30867       0.88      0.761       0.82      0.574\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      65/99       7.3G    0.03885    0.03482   0.003571        915        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       2160      30867      0.879      0.762       0.82      0.574\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      66/99       7.3G    0.03886    0.03468   0.003551        690        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       2160      30867      0.875      0.762       0.82      0.575\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      67/99       7.3G    0.03865    0.03465   0.003541        685        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       2160      30867      0.876      0.763      0.821      0.575\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      68/99       7.3G    0.03867    0.03471   0.003558        915        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       2160      30867      0.862      0.772      0.821      0.576\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      69/99       7.3G    0.03853    0.03444   0.003543        593        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       2160      30867      0.861      0.773      0.822      0.576\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      70/99       7.3G    0.03841    0.03424   0.003512        640        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       2160      30867       0.86      0.773      0.822      0.576\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      71/99       7.3G    0.03832    0.03427   0.003494        581        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       2160      30867      0.861      0.773      0.821      0.576\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      72/99       7.3G    0.03824    0.03421   0.003507        812        640: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       2160      30867      0.864      0.773      0.821      0.577\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      73/99       7.3G    0.03881    0.03465   0.003457        701        640:  "
          ]
        }
      ],
      "source": [
        "SCRIPT_ROOT = \"/home/aidev/workspace/ClassifyImages/\"\n",
        "DATA_ROOT = \"/home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/\"\n",
        "train_folder = DATA_ROOT + \"train\"\n",
        "val_folder = DATA_ROOT + \"val\"\n",
        "\n",
        "def train_yolo(train_data_path, val_data_path, batch_size=32, epochs=100, weights_path=None):\n",
        "\n",
        "  if weights_path is None:\n",
        "    weights_path = \"yolov5s.pt\"\n",
        "\n",
        "  cfg_yaml = SCRIPT_ROOT + \"data/configs/train_cfg_childzone.yaml\"\n",
        "  data_yaml = SCRIPT_ROOT + \"data/configs/yolov5_train_childzone_ai-hub.yaml\"\n",
        "\n",
        "  !echo train.py --img 640 --batch $batch_size --epochs $epochs --data $data_yaml --cfg $cfg_yaml --weights $weights_path --cache\n",
        "  !python3 train.py --img 640 --batch $batch_size --epochs $epochs --data $data_yaml --cfg $cfg_yaml --weights $weights_path --cache\n",
        "\n",
        "train_yolo(train_folder,\n",
        "           val_folder,\n",
        "           batch_size=32,\n",
        "           epochs=100,\n",
        "           weights_path=\"yolov5s.pt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ki3fla1eLG3g"
      },
      "source": [
        "# Validate with Test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%cd /home/aidev/workspace/yolov5\n",
        "!pwd\n",
        "!ls -al"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLP0zOJQYERZ",
        "outputId": "acdc17c4-263c-4aaa-c286-be2da0885aa1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "weights_path is /home/aidev/workspace/ClassifyImages/yolov5-train/tw/weights/best.pt\n",
            "val.py --weights /home/aidev/workspace/ClassifyImages/yolov5-train/tw/weights/best.pt --img 640 --conf 0.5 --data /home/aidev/workspace/ClassifyImages/data/configs/yolov5_childzone_validate.yaml\n",
            "\u001b[34m\u001b[1mval: \u001b[0mdata=/home/aidev/workspace/ClassifyImages/data/configs/yolov5_childzone_validate.yaml, weights=['/home/aidev/workspace/ClassifyImages/yolov5-train/tw/weights/best.pt'], batch_size=32, imgsz=640, conf_thres=0.5, iou_thres=0.6, max_det=300, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=exp, exist_ok=False, half=False, dnn=False\n",
            "WARNING ⚠️ confidence threshold 0.5 > 0.001 produces invalid results\n",
            "YOLOv5 🚀 v7.0-72-g064365d8 Python-3.10.6 torch-1.13.1+cu117 CUDA:0 (NVIDIA GeForce RTX 3080 Ti, 12037MiB)\n",
            "\n",
            "Fusing layers... \n",
            "train_cfg_child_zone summary: 166 layers, 7078183 parameters, 0 gradients\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/aidev/data/AI-Hub/ChildZoneCCTV/run-tw-flat/test... 2160 ima\u001b[0m\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-tw-flat/test/2020_11_25_17_40_with_dog_night_A_01_00094.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-tw-flat/test/2020_11_25_17_40_with_dog_night_A_01_00097.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-tw-flat/test/2020_11_25_17_40_with_dog_night_A_01_00118.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-tw-flat/test/2020_11_25_17_40_with_dog_night_A_01_00123.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-tw-flat/test/2020_11_25_17_40_with_dog_night_A_01_00124.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-tw-flat/test/2020_11_25_17_40_with_dog_night_A_01_00126.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-tw-flat/test/2020_11_25_17_40_with_dog_night_A_01_00150.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-tw-flat/test/2020_11_25_17_40_with_dog_night_A_01_00160.jpg: 3 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-tw-flat/test/2020_11_25_17_40_with_dog_night_A_01_00163.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-tw-flat/test/2020_12_02_16_07_ride_cycle_sun_A_05_00103.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-tw-flat/test/2020_12_02_16_07_ride_cycle_sun_A_05_00110.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/aidev/data/AI-Hub/ChildZoneCCTV/run-tw-flat/test.cache\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       2160      31233      0.955      0.834      0.908      0.738\n",
            "                person       2160       7116      0.939      0.852      0.918       0.72\n",
            "               vehicle       2160      14547      0.948      0.869      0.929      0.825\n",
            "                 cycle       2160        715      0.981       0.94      0.969      0.876\n",
            "                  kick       2160        521      0.973      0.693      0.838       0.57\n",
            "                  face       2160        935      0.847      0.561      0.726      0.396\n",
            "         license_plate       2160       2154      0.968      0.882      0.938      0.782\n",
            "              umbrella       2160        476      0.968      0.954      0.975      0.788\n",
            "         traffic_light       2160       4353       0.99      0.909      0.954      0.869\n",
            "             motorbike       2160        416      0.981      0.846      0.921      0.816\n",
            "Speed: 0.1ms pre-process, 1.0ms inference, 0.8ms NMS per image at shape (32, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/val/exp4\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "DATA_ROOT = \"/home/aidev/data/AI-Hub/ChildZoneCCTV/run-tw-flat/\"\n",
        "\n",
        "def val_yolo(data_yaml, conf=0.5, weights_path=None):\n",
        "  # data_yaml = DATA_ROOT + \"yolov5_childzone_validate.yaml\"\n",
        "  # create_yaml(DATA_ROOT + \"yolov5_childzone_validate.yaml\", data_yaml, dict({\"val\": val_data_path}))\n",
        "\n",
        "  # if weights_path is None:\n",
        "  #   weights_path = \"yolov5s.pt\"\n",
        "  cfg_yaml = DATA_ROOT + \"train_cfg_child_zone.yaml\"\n",
        "  # create_yaml(\"/home/aidev/workspace/ClassifyImages/data/configs/train_cfg_child_zone.yaml\", cfg_yaml, dict({\"nc\": 10}))\n",
        "  print(\"weights_path is {}\".format(weights_path))\n",
        "\n",
        "  !echo val.py --weights $weights_path --img 640 --conf $conf --data $data_yaml\n",
        "\n",
        "  !python3 val.py --weights $weights_path --img 640 --conf $conf --data $data_yaml\n",
        "  # !python3 val.py --weights \"/home/aidev/ClassifyImages/yolov5-train/tw/weights/best.pt\" --img 640 --conf /home/aidev/data/AI-Hub/ChildZoneCCTV/run-tw-flat/train_cfg_child_zone.yaml --data /home/aidev/data/AI-Hub/ChildZoneCCTV/run-tw-flat/yolov5_childzone_validate.yaml\n",
        "\n",
        "val_yolo(\"/home/aidev/workspace/ClassifyImages/data/configs/yolov5_childzone_validate.yaml\", conf=0.5, weights_path=\"/home/aidev/workspace/ClassifyImages/yolov5-train/tw/weights/best.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "2iKO_l6avgM1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "weights_path is /home/aidev/workspace/yolov5/runs/train/exp11/weights/best.pt\n",
            "val.py --weights /home/aidev/workspace/yolov5/runs/train/exp11/weights/best.pt --img 640 --conf 0.5 --data /home/aidev/workspace/ClassifyImages/data/configs/yolov5_childzone_validate.yaml\n",
            "\u001b[34m\u001b[1mval: \u001b[0mdata=/home/aidev/workspace/ClassifyImages/data/configs/yolov5_childzone_validate.yaml, weights=['/home/aidev/workspace/yolov5/runs/train/exp11/weights/best.pt'], batch_size=32, imgsz=640, conf_thres=0.5, iou_thres=0.6, max_det=300, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=exp, exist_ok=False, half=False, dnn=False\n",
            "WARNING ⚠️ confidence threshold 0.5 > 0.001 produces invalid results\n",
            "YOLOv5 🚀 v7.0-72-g064365d8 Python-3.10.6 torch-1.13.1+cu117 CUDA:0 (NVIDIA GeForce RTX 3080 Ti, 12037MiB)\n",
            "\n",
            "Fusing layers... \n",
            "train_cfg summary: 166 layers, 7078183 parameters, 0 gradients\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/aidev/data/AI-Hub/ChildZoneCCTV/run-tw-flat/test.cache... 21\u001b[0m\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-tw-flat/test/2020_11_25_17_40_with_dog_night_A_01_00094.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-tw-flat/test/2020_11_25_17_40_with_dog_night_A_01_00097.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-tw-flat/test/2020_11_25_17_40_with_dog_night_A_01_00118.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-tw-flat/test/2020_11_25_17_40_with_dog_night_A_01_00123.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-tw-flat/test/2020_11_25_17_40_with_dog_night_A_01_00124.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-tw-flat/test/2020_11_25_17_40_with_dog_night_A_01_00126.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-tw-flat/test/2020_11_25_17_40_with_dog_night_A_01_00150.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-tw-flat/test/2020_11_25_17_40_with_dog_night_A_01_00160.jpg: 3 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-tw-flat/test/2020_11_25_17_40_with_dog_night_A_01_00163.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-tw-flat/test/2020_12_02_16_07_ride_cycle_sun_A_05_00103.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-tw-flat/test/2020_12_02_16_07_ride_cycle_sun_A_05_00110.jpg: 5 duplicate labels removed\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       2160      31233      0.948      0.812      0.894      0.718\n",
            "                person       2160       7116      0.944      0.846      0.915      0.705\n",
            "               vehicle       2160      14547      0.944      0.866      0.927      0.815\n",
            "                 cycle       2160        715       0.99      0.927      0.963      0.867\n",
            "                  kick       2160        521      0.937      0.566      0.763        0.5\n",
            "                  face       2160        935      0.852      0.523      0.704      0.377\n",
            "         license_plate       2160       2154      0.937      0.873      0.931      0.771\n",
            "              umbrella       2160        476      0.974      0.956      0.976      0.774\n",
            "         traffic_light       2160       4353      0.989      0.906      0.952      0.852\n",
            "             motorbike       2160        416      0.962      0.844      0.917      0.804\n",
            "Speed: 0.1ms pre-process, 1.0ms inference, 0.8ms NMS per image at shape (32, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/val/exp8\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "val_yolo(\"/home/aidev/workspace/ClassifyImages/data/configs/yolov5_childzone_validate.yaml\", conf=0.5, weights_path=\"/home/aidev/workspace/yolov5/runs/train/exp11/weights/best.pt\")\n",
        "# val_yolo(\"/content/drive/MyDrive/data/Top15/test_top15/top15_0\", conf=0.5, weights_path=\"/content/drive/MyDrive/data/Top15/runs/train/train15_0/weights/best.pt\")\n",
        "# !mv runs/val/exp /content/drive/MyDrive/data/Top15/runs/test/test15_0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "weights_path is /home/aidev/workspace/yolov5/runs/train/exp10/weights/best.pt\n",
            "val.py --weights /home/aidev/workspace/yolov5/runs/train/exp10/weights/best.pt --img 640 --conf 0.5 --data /home/aidev/workspace/ClassifyImages/data/configs/yolov5_childzone_validate.yaml\n",
            "\u001b[34m\u001b[1mval: \u001b[0mdata=/home/aidev/workspace/ClassifyImages/data/configs/yolov5_childzone_validate.yaml, weights=['/home/aidev/workspace/yolov5/runs/train/exp10/weights/best.pt'], batch_size=32, imgsz=640, conf_thres=0.5, iou_thres=0.6, max_det=300, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=exp, exist_ok=False, half=False, dnn=False\n",
            "WARNING ⚠️ confidence threshold 0.5 > 0.001 produces invalid results\n",
            "YOLOv5 🚀 v7.0-72-g064365d8 Python-3.10.6 torch-1.13.1+cu117 CUDA:0 (NVIDIA GeForce RTX 3080 Ti, 12037MiB)\n",
            "\n",
            "Fusing layers... \n",
            "train_cfg summary: 166 layers, 7078183 parameters, 0 gradients\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/aidev/data/AI-Hub/ChildZoneCCTV/run-tw-flat/test.cache... 21\u001b[0m\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-tw-flat/test/2020_11_25_17_40_with_dog_night_A_01_00094.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-tw-flat/test/2020_11_25_17_40_with_dog_night_A_01_00097.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-tw-flat/test/2020_11_25_17_40_with_dog_night_A_01_00118.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-tw-flat/test/2020_11_25_17_40_with_dog_night_A_01_00123.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-tw-flat/test/2020_11_25_17_40_with_dog_night_A_01_00124.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-tw-flat/test/2020_11_25_17_40_with_dog_night_A_01_00126.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-tw-flat/test/2020_11_25_17_40_with_dog_night_A_01_00150.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-tw-flat/test/2020_11_25_17_40_with_dog_night_A_01_00160.jpg: 3 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-tw-flat/test/2020_11_25_17_40_with_dog_night_A_01_00163.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-tw-flat/test/2020_12_02_16_07_ride_cycle_sun_A_05_00103.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-tw-flat/test/2020_12_02_16_07_ride_cycle_sun_A_05_00110.jpg: 5 duplicate labels removed\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       2160      31233      0.645      0.269      0.465      0.318\n",
            "                person       2160       7116      0.763      0.404      0.598      0.336\n",
            "               vehicle       2160      14547      0.719      0.399      0.589      0.393\n",
            "                 cycle       2160        715      0.301     0.0476      0.159      0.102\n",
            "                  kick       2160        521      0.969      0.359      0.666       0.45\n",
            "                  face       2160        935      0.413      0.061      0.238      0.102\n",
            "         license_plate       2160       2154      0.846      0.186      0.525      0.363\n",
            "              umbrella       2160        476          0          0          0          0\n",
            "         traffic_light       2160       4353      0.879      0.705      0.816       0.61\n",
            "             motorbike       2160        416      0.917      0.264      0.597      0.508\n",
            "Speed: 0.1ms pre-process, 1.0ms inference, 0.7ms NMS per image at shape (32, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/val/exp9\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "val_yolo(\"/home/aidev/workspace/ClassifyImages/data/configs/yolov5_childzone_validate.yaml\", conf=0.5, weights_path=\"/home/aidev/workspace/yolov5/runs/train/exp10/weights/best.pt\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## AI-Hub model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/aidev/workspace/yolov5\n",
            "/home/aidev/workspace/yolov5\n",
            "weights_path is /home/aidev/workspace/ClassifyImages/yolov5-train/ai-hub/weights/best.pt\n",
            "val.py --weights /home/aidev/workspace/ClassifyImages/yolov5-train/ai-hub/weights/best.pt --img 640 --conf 0.5 --data /home/aidev/workspace/ClassifyImages/data/configs/yolov5_childzone_validate.yaml\n",
            "\u001b[34m\u001b[1mval: \u001b[0mdata=/home/aidev/workspace/ClassifyImages/data/configs/yolov5_childzone_validate.yaml, weights=['/home/aidev/workspace/ClassifyImages/yolov5-train/ai-hub/weights/best.pt'], batch_size=32, imgsz=640, conf_thres=0.5, iou_thres=0.6, max_det=300, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=exp, exist_ok=False, half=False, dnn=False\n",
            "WARNING ⚠️ confidence threshold 0.5 > 0.001 produces invalid results\n",
            "YOLOv5 🚀 v7.0-72-g064365d8 Python-3.10.6 torch-1.13.1+cu117 CUDA:0 (NVIDIA GeForce RTX 3080 Ti, 12037MiB)\n",
            "\n",
            "Fusing layers... \n",
            "train_cfg_childzone summary: 166 layers, 7078183 parameters, 0 gradients\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/aidev/data/AI-Hub/ChildZoneCCTV/run-tw-flat/test.cache... 21\u001b[0m\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-tw-flat/test/2020_11_25_17_40_with_dog_night_A_01_00094.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-tw-flat/test/2020_11_25_17_40_with_dog_night_A_01_00097.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-tw-flat/test/2020_11_25_17_40_with_dog_night_A_01_00118.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-tw-flat/test/2020_11_25_17_40_with_dog_night_A_01_00123.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-tw-flat/test/2020_11_25_17_40_with_dog_night_A_01_00124.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-tw-flat/test/2020_11_25_17_40_with_dog_night_A_01_00126.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-tw-flat/test/2020_11_25_17_40_with_dog_night_A_01_00150.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-tw-flat/test/2020_11_25_17_40_with_dog_night_A_01_00160.jpg: 3 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-tw-flat/test/2020_11_25_17_40_with_dog_night_A_01_00163.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-tw-flat/test/2020_12_02_16_07_ride_cycle_sun_A_05_00103.jpg: 5 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/aidev/data/AI-Hub/ChildZoneCCTV/run-tw-flat/test/2020_12_02_16_07_ride_cycle_sun_A_05_00110.jpg: 5 duplicate labels removed\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       2160      31233      0.913       0.69      0.817      0.578\n",
            "                person       2160       7116      0.927      0.764      0.868      0.586\n",
            "               vehicle       2160      14547       0.93      0.779      0.877      0.679\n",
            "                 cycle       2160        715      0.968        0.8      0.896       0.72\n",
            "                  kick       2160        521       0.91      0.311      0.618      0.377\n",
            "                  face       2160        935      0.721      0.301      0.509      0.201\n",
            "         license_plate       2160       2154      0.921      0.768      0.871      0.624\n",
            "              umbrella       2160        476      0.966      0.836      0.913      0.608\n",
            "         traffic_light       2160       4353      0.953      0.857      0.924      0.742\n",
            "             motorbike       2160        416       0.92      0.798      0.881      0.666\n",
            "Speed: 0.1ms pre-process, 1.0ms inference, 0.8ms NMS per image at shape (32, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/val/exp11\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "%cd /home/aidev/workspace/yolov5\n",
        "!pwd\n",
        "DATA_ROOT = \"/home/aidev/data/AI-Hub/ChildZoneCCTV/run-ai-hub/\"\n",
        "\n",
        "def val_yolo(data_yaml, conf=0.5, weights_path=None):\n",
        "  cfg_yaml = DATA_ROOT + \"train_cfg_child_zone.yaml\"\n",
        "  print(\"weights_path is {}\".format(weights_path))\n",
        "\n",
        "  !echo val.py --weights $weights_path --img 640 --conf $conf --data $data_yaml\n",
        "\n",
        "  !python3 val.py --weights $weights_path --img 640 --conf $conf --data $data_yaml\n",
        "\n",
        "val_yolo(\"/home/aidev/workspace/ClassifyImages/data/configs/yolov5_childzone_validate.yaml\", conf=0.5, weights_path=\"/home/aidev/workspace/ClassifyImages/yolov5-train/ai-hub/weights/best.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyPFeyejc/tGVDijwq+gQwMP",
      "include_colab_link": true,
      "machine_shape": "hm",
      "name": "train_dashboard_top15.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
